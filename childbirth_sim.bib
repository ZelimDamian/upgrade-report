% REVERSE ENGINEERING

@article{chikofsky1990reverse,
  title={Reverse engineering and design recovery: A taxonomy},
  author={Chikofsky, E.J. and Cross, J.H. and others},
  journal={Software, IEEE},
  volume={7},
  number={1},
  pages={13--17},
  year={1990},
  publisher={IEEE}
}

@article{philippow2005approach,
  title={An approach for reverse engineering of design patterns},
  author={Philippow, I. and Streitferdt, D. and Riebisch, M. and Naumann, S.},
  journal={Software and Systems Modeling},
  volume={4},
  number={1},
  pages={55--70},
  year={2005},
  publisher={Springer}
}

@article{roscoelooking,
  title={Looking Forwards to Going Backwards: An Assessment of Current Reverse Engineering},
  author={Roscoe, J.F.},
  year={2011},
  journal={Current Issues in Software Engineering}
}

@inproceedings{arcelli2005comparison,
  title={A comparison of reverse engineering tools based on design pattern decomposition},
  author={Arcelli, F. and Masiero, S. and Raibulet, C. and Tisato, F.},
  booktitle={Software Engineering Conference, 2005. Proceedings. 2005 Australian},
  pages={262--269},
  year={2005},
  organization={IEEE}
}

@article{counsell2004design,
  title={Design level hypothesis testing through reverse engineering of object-oriented software},
  author={Counsell, S. and Newson, P. and Mendes, E.},
  journal={International Journal of Software Engineering and Knowledge Engineering},
  volume={14},
  number={02},
  pages={207--220},
  year={2004},
  publisher={World Scientific}
}

@inproceedings{uchiyama2011design,
  title={Design Pattern Detection using Software Metrics and Machine Learning},
  author={Uchiyama, S. and Washizaki, H. and Fukazawa, Y. and Kubo, A.},
  booktitle={First International Workshop on Model-Driven Software Migration (MDSM 2011)},
  pages={38},
  year={2011}
}

@inproceedings{meyer2006pattern,
  title={Pattern-based reengineering of software systems},
  author={Meyer, M.},
  booktitle={Reverse Engineering, 2006. WCRE'06. 13th Working Conference on},
  pages={305--306},
  year={2006},
  organization={IEEE}
}

@misc{reverseengineeringdictionary,
  title = {Merriam-Webster Dictionary},
  author = {Merriam-Webster},
  howpublished = {\url{http://www.merriam-webster.com/dictionary/reverse\%20engineering}},
  year = {2012},
  note = {[Online; accessed December 2012]}
}


@inproceedings{shi2006reverse,
  title={Reverse engineering of design patterns from java source code},
  author={Shi, N. and Olsson, R.A.},
  booktitle={Automated Software Engineering, 2006. ASE'06. 21st IEEE/ACM International Conference on},
  pages={123--134},
  year={2006},
  organization={IEEE}
}

@article{flores2005reverse,
  title={Reverse engineering of framework design using a meta-patterns-based approach},
  author={Flores, N. and Aguiar, A.},
  journal={Software Stability: Timeless Architectures and System of Patterns},
  pages={10},
  year={2005},
  publisher={Citeseer}
}

@article{rasoolsurvey,
  title={A Survey on Design Pattern Recovery Techniques},
  author={Rasool, G. and Streitfdert, D.},
  journal={International Journal of Computing Science Issues},
  volume={8},
  year={2011}
}

@inproceedings{cerulo2006use,
  title={On the use of process trails to understand software development},
  author={Cerulo, L.},
  booktitle={Reverse Engineering, 2006. WCRE'06. 13th Working Conference on},
  pages={303--304},
  year={2006},
  organization={IEEE}
}

@book{gamma1995design,
  title={Design patterns: elements of reusable object-oriented software},
  author={Gamma, E. and Helm, R. and Johnson, R. and Vlissides, J.},
  year={1995},
  publisher={Addison-Wesley Professional}
}

@article{jones2003abstract,
  title={Abstract syntax tree implementation idioms},
  author={Jones, J.},
  journal={Pattern Languages of Program Design},
  year={2003}
}

@inproceedings{fischer2007abstract,
  title={Abstract syntax trees-and their role in model driven software development},
  author={Fischer, G. and Lusiardi, J. and von Gudenberg, J.W.},
  booktitle={Software Engineering Advances, 2007. ICSEA 2007. International Conference on},
  pages={38--38},
  year={2007},
  organization={IEEE}
}

@INPROCEEDINGS{misek2010mapping, 
author={Misek, J. and Zavoral, F.}, 
booktitle={Computer and Information Science (ICIS), 2010 IEEE/ACIS 9th International Conference on}, title={Mapping of Dynamic Language Constructs into Static Abstract Syntax Trees}, 
year={2010}, 
month={aug.}, 
volume={}, 
number={}, 
pages={625 -630}, 
keywords={Assembly;Documentation;Reflection;Runtime;Semantics;Syntactics;XML;program compilers;program diagnostics;programming language semantics;Phalanger;automatic code analysis;compiler;dynamic PHP language;dynamic language mapping;semantic metadata extraction;source code prediction;static abstract syntax trees;static code analyzers;IntelliSense;PHP;abstract syntax tree;code analysis;dynamic language;prediction;}, 
doi={10.1109/ICIS.2010.100}, 
ISSN={},}

@misc{omgastm,
  title={Architecture-driven Moderization: Abstract Syntax Tree Metamodel (ASTM)},
  author={OMG and others},
  journal={OMG Document},
  year={2011},
  howpublished={\url{http://www.omg.org/spec/ASTM}},
  note = {[Online; accessed December 2012]}
}

@inproceedings{raghavan2004dex,
  title={Dex: A semantic-graph differencing tool for studying changes in large code bases},
  author={Raghavan, S. and Rohana, R. and Leon, D. and Podgurski, A. and Augustine, V.},
  booktitle={Software Maintenance, 2004. Proceedings. 20th IEEE International Conference on},
  pages={188--197},
  year={2004},
  organization={IEEE}
}

@inproceedings{mamas2000towards,
  title={Towards portable source code representations using XML},
  author={Mamas, E. and Kontogiannis, K.},
  booktitle={Reverse Engineering, 2000. Proceedings. Seventh Working Conference on},
  pages={172--182},
  year={2000},
  organization={IEEE}
}

@misc{omgxmi,
  title={OMG MOF 2 XMI Mapping Specification},
  author={OMG and others},
  journal={OMG Document},
  year={2011},
  howpublished={\url{http://www.omg.org/spec/XMI/2.4.1}},
  note = {[Online; accessed December 2012]}
}

@misc{omgmof,
  title={OMG Meta Object Facility (MOF) Core Specification},
  author={OMG and others},
  journal={OMG Document},
  year={2011},
  howpublished={\url{http://www.omg.org/spec/MOF/2.4.1}},
  note = {[Online; accessed December 2012]}
}

@misc{omguml,
  title={Unified Modelling Language: Infrastructure},
  author={OMG and others},
  journal={OMG Document},
  year={2005},
  howpublished={\url{http://www.omg.org/spec/UML/2.0/}},
  note = {[Online; accessed December 2012]}
}

@misc{fujaba,
  title={Fujaba Tool Suite},
  author={Fujaba},
  year={2012},
  howpublished={\url{http://www.fujaba.de}},
  note = {[Online; accessed December 2012]}
}

@misc{pinot,
  title={Pattern Inference and Recovery Tool (PINOT)},
  author={PINOT},
  year={2012},
  howpublished={\url{http://www.cs.ucdavies.edu/~shini/research/pinot}},
  note = {[Online; accessed December 2012]}
}

@misc{spool,
  title={SPOOL},
  author={SPOOL},
  year={2012},
  howpublished={\url{http://www.iro.montreal.ca/~keller/Spool/main.html}},
  note = {[Online; accessed December 2012]}
}

@article{demima,
 author = {Gu{\'e}h{\'e}neuc, Yann-Ga\"{e}l and Antoniol, Giuliano},
 title = {DeMIMA: A Multilayered Approach for Design Pattern Identification},
 journal = {IEEE Trans. Softw. Eng.},
 issue_date = {September 2008},
 volume = {34},
 number = {5},
 month = sep,
 year = {2008},
 issn = {0098-5589},
 pages = {667--684},
 numpages = {18},
 url = {http://dx.doi.org/10.1109/TSE.2008.48},
 doi = {10.1109/TSE.2008.48},
 acmid = {1439212},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
 keywords = {Object-Oriented Programming, Object-Oriented Programming, Patterns, Patterns},
} 

@INPROCEEDINGS{columbus, 
author={Ferenc, R. and Beszedes, A. and Tarkiainen, M. and Gyimothy, T.}, 
booktitle={Software Maintenance, 2002. Proceedings. International Conference on}, title={Columbus - reverse engineering tool and schema for C++}, 
year={2002}, 
month={}, 
volume={}, 
number={}, 
pages={ 172 - 181}, 
keywords={Artificial intelligence;Computer architecture;Data mining;Data visualization;Filtering;Large-scale systems;Programming;Reverse engineering;Software maintenance;Software systems; C++ language; object-oriented programming; reverse engineering; software maintenance; software tools; systems re-engineering; C++ analyzer; Columbus; large C++ projects; large-scale software development; large-scale software maintenance; reengineering; reverse engineering schema; reverse engineering tool; toolset;}, 
doi={10.1109/ICSM.2002.1167764}, 
ISSN={1063-6773}}

@misc{agilej,
  title={AgileJ Structure Views},
  author={AgileJ},
  year={2012},
  howpublished={\url{http://www.agilej.com/}},
  note = {[Online; accessed December 2012]}
}

@misc{umodel,
  title={Altova UModel},
  author={Altova},
  year={2012},
  howpublished={\url{http://www.altova.com/umodel.html}},
  note = {[Online; accessed December 2012]}
}

@misc{argouml,
  title={ArgoUML},
  author={ArgoUML},
  year={2012},
  howpublished={\url{http://argouml.tigris.org/}},
  note = {[Online; accessed December 2012]}
}

@misc{astah,
  title={Astah Professional},
  author={ChangeVision},
  year={2012},
  howpublished={\url{http://astah.net/editions/professional}},
  note = {[Online; accessed December 2012]}
}

@misc{bouml,
  title={BOUML},
  author={Pages, B.},
  year={2012},
  howpublished={\url{http://www.bouml.fr}},
  note = {[Online; accessed December 2012]}
}

@misc{enterprisearchitect,
  title={Enterprise Architect},
  author={SparxSystems},
  year={2012},
  howpublished={\url{http://www.sparxsystems.com/products/ea/index.html}},
  note = {[Online; accessed December 2012]}
}

@misc{rationalrhapsody,
  title={Rational Rhapsody},
  author={IBM},
  year={2012},
  howpublished={\url{http://www-142.ibm.com/software/products/us/en/ratirhapfami/}},
  note = {[Online; accessed December 2012]}
}

@misc{magicdraw,
  title={MagicDraw UML},
  author={NoMagic},
  year={2012},
  howpublished={\url{http://www.nomagic.com/products/magicdraw/magicdraw-enterprise.html}},
  note = {[Online; accessed December 2012]}
}

@misc{modelio,
  title={Modelio},
  author={Modeliosoft},
  year={2012},
  howpublished={\url{http://www.modeliosoft.com}},
  note = {[Online; accessed December 2012]}
}

@misc{objectif,
  title={objectiF},
  author={Microtool},
  year={2012},
  howpublished={\url{http://www.microtool.de/objectif/en/}},
  note = {[Online; accessed December 2012]}
}

@misc{softwareideasmodeller,
  title={Software Ideas Modeller},
  author={Rodina, D.},
  year={2012},
  howpublished={\url{http://www.softwareideas.net}},
  note = {[Online; accessed December 2012]}
}

@misc{staruml,
  title={StarUML},
  author={StarUML},
  year={2008},
  howpublished={\url{http://staruml.sourceforge.net/en/}},
  note = {[Online; accessed December 2012]}
}

@misc{umbrello,
  title={Umbrello UML Modeller},
  author={Umbrello},
  year={2012},
  howpublished={\url{http://uml.sourceforge.net}},
  note = {[Online; accessed December 2012]}
}

@misc{visualparadigm,
  title={Visual Paradigm for UML},
  author={VisualParadigm},
  year={2012},
  howpublished={\url{http://www.visual-paradigm.com/product/vpuml/}},
  note = {[Online; accessed December 2012]}
}

@misc{rationalrose,
  title={Rational Rose},
  author={IBM},
  year={2012},
  howpublished={\url{http://www-01.ibm.com/software/awdtools/developer/rose/}},
  note = {[Online; accessed December 2012]}
}

@misc{borlandtogether,
  title={Borland Together},
  author={Borland},
  year={2012},
  howpublished={\url{http://www.borland.com/products/Together/}},
  note = {[Online; accessed December 2012]}
}


% Additional for RED-BM

@inproceedings{sim2003using,
  title={Using benchmarking to advance research: A challenge to software engineering},
  author={Sim, Susan Elliott and Easterbrook, Steve and Holt, Richard C},
  booktitle={Proceedings of the 25th International Conference on Software Engineering},
  pages={74--83},
  year={2003},
  organization={IEEE Computer Society}
}

@inproceedings{bellay1997comparison,
  title={A comparison of four reverse engineering tools},
  author={Bellay, Berndt and Gall, Harald},
  booktitle={Reverse Engineering, 1997. Proceedings of the Fourth Working Conference on},
  pages={2--11},
  year={1997},
  organization={IEEE}
}

@article{koschke2003software,
  title={Software visualization in software maintenance, reverse engineering, and re-engineering: a research survey},
  author={Koschke, Rainer},
  journal={Journal of Software Maintenance and Evolution: Research and Practice},
  volume={15},
  number={2},
  pages={87--109},
  year={2003},
  publisher={Wiley Online Library}
}

@article{roman1993taxonomy,
  title={A taxonomy of program visualization systems},
  author={Roman, G-C and Cox, Kenneth C.},
  journal={Computer},
  volume={26},
  number={12},
  pages={11--24},
  year={1993},
  publisher={IEEE}
}

@misc{redbm,
	title={Reverse Engineering to Design Benchmark},
	author={UEA},
	year={2013},
	howpublished={\url{http://www.uea.ac.uk/computing/machine-learning/traceability-forensics/reverse-engineering}},
    note = {[Online; accessed May 2013]}
}

@book{fenton1998software,
  title={Software metrics: a rigorous and practical approach},
  author={Fenton, Norman E and Pfleeger, Shari Lawrence},
  year={1998},
  publisher={PWS Publishing Co.}
}

@article{quan2012additive,
  title={Additive-State-Decomposition-Based Tracking Control for TORA Benchmark},
  author={Quan, Quan and Cai, Kai-Yuan},
  journal={arXiv preprint arXiv:1211.6827},
  year={2012}
}

@article{bonutti2012benchmarking,
  title={Benchmarking curriculum-based course timetabling: formulations, data formats, instances, validation, visualization, and results},
  author={Bonutti, Alex and De Cesco, Fabio and Di Gaspero, Luca and Schaerf, Andrea},
  journal={Annals of Operations Research},
  volume={194},
  number={1},
  pages={59--70},
  year={2012},
  publisher={Springer}
}

@inproceedings{kleinbenchmarking,
  title={Benchmarking infrastructure for mutation text mining},
  author={Klein, Artjom and Riazanov, Alexandre and Hindle, Matthew M and Baker, Christopher JO},
  year={2012},
  booktitle={Annotation, Interpretation and Management of Mutations}
}

@article{olivier2012benchmarking,
  title={On benchmarking embedded Linux flash file systems},
  author={Olivier, Pierre and Boukhobza, Jalil and Senn, Eric},
  journal={arXiv preprint arXiv:1208.6391},
  year={2012}
}

@article{gaul2012function,
  title={Function call overhead benchmarks with MATLAB, Octave, Python, Cython and C},
  author={Gaul, Andr{\'e}},
  journal={arXiv preprint arXiv:1202.2736},
  year={2012}
}

@article{gherardi2012java,
  title={A Java vs. C++ performance evaluation: a 3D modeling benchmark},
  author={Gherardi, Luca and Brugali, Davide and Comotti, Daniele},
  journal={Simulation, Modeling, and Programming for Autonomous Robots},
  pages={161--172},
  year={2012},
  publisher={Springer}
}

@inproceedings{arasu2004linear,
  title={Linear road: A stream data management benchmark},
  author={Arasu, Arvind and Cherniack, Mitch and Galvez, Eduardo and Maier, David and Maskey, Anurag and Ryvkina, Esther and Stonebraker, Michael and Tibbetts, Richard and others},
  booktitle={Proceedings of the International Conference on Very Large Data Bases},
  pages={480--491},
  year={2004}
}

@article{kumar2012benchmarking,
  title={Benchmarking recognition results on word image datasets},
  author={Kumar, Deepak and Prasad, MN and Ramakrishnan, AG},
  journal={arXiv preprint arXiv:1208.6137},
  year={2012}
}

@inproceedings{bays2012spec,
  title={SPEC: driving better benchmarks},
  author={Bays, Walter and Lange, Klaus-Dieter},
  booktitle={Proceedings of the third joint WOSP/SIPEW international conference on Performance Engineering},
  pages={249--250},
  year={2012},
  organization={ACM}
}

@inproceedings{fulop2008towards,
  title={Towards a benchmark for evaluating reverse engineering tools},
  author={Fulop, LJ and Hegedus, P{\'e}ter and Ferenc, Rudolf and Gyim{\'o}thy, Tibor},
  booktitle={Reverse Engineering, 2008. WCRE'08. 15th Working Conference on},
  pages={335--336},
  year={2008},
  organization={IEEE}
}

@article{bellon2007comparison,
  title={Comparison and evaluation of clone detection tools},
  author={Bellon, Stefan and Koschke, Rainer and Antoniol, Giulio and Krinke, Jens and Merlo, Ettore},
  journal={Software Engineering, IEEE Transactions on},
  volume={33},
  number={9},
  pages={577--591},
  year={2007},
  publisher={IEEE}
}

@article{pettersson2010evaluation,
  title={Evaluation of accuracy in design pattern occurrence detection},
  author={Pettersson, Niklas and Lowe, Welf and Nivre, Joakim},
  journal={Software Engineering, IEEE Transactions on},
  volume={36},
  number={4},
  pages={575--590},
  year={2010},
  publisher={IEEE}
}

% TRACEABILITY LIT

@inproceedings{gotel1994analysis,
  title={An analysis of the requirements traceability problem},
  author={Gotel, O.C.Z. and Finkelstein, CW},
  booktitle={Requirements Engineering, 1994., Proceedings of the First International Conference on},
  pages={94--101},
  year={1994},
  organization={IEEE}
}



@inproceedings{asuncion2007end,
  title={An end-to-end industrial software traceability tool},
  author={Asuncion, H.U. and Fran{\c{c}}ois, F. and Taylor, R.N.},
  booktitle={Foundations of Software Engineering: Proceedings of the the 6 th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering},
  volume={3},
  number={07},
  pages={115--124},
  year={2007}
}

@techreport{harrington1993investigation,
  title={An Investigation of Requirements Traceability to Support Systems Development},
  author={Harrington, G.A. and Rondeau, K.M.},
  year={1993},
  institution={DTIC Document}
}

@article{spanoudakis2005software,
  title={Software traceability: a roadmap},
  author={Spanoudakis, G. and Zisman, A.},
  journal={Handbook of Software Engineering and Knowledge Engineering},
  volume={3},
  pages={395--428},
  year={2005},
  publisher={World Scientific Publishing Co}
}

@book{cleland2012software,
  title={Software and Systems Traceability},
  author={Cleland-Huang, J. and Gotel, O. and Zisman, A.},
  year={2012},
  publisher={Springer}
}

@techreport{edwards1991methodology,
  title={A methodology for systems requirements specification and traceability for large real time complex systems},
  author={Edwards, Michael and Howell, Steven L},
  year={1991},
  institution={DTIC Document}
}

@article{naur1969software,
  title={Software Engineering: Report of a conference sponsored by the NATO Science Committee, Garmisch, Germany, 7-11 Oct. 1968, Brussels, Scientific Affairs Division, NATO},
  author={Naur, Peter and Randell, Brian},
  year={1969}
}

@inproceedings{boehm1976quantitative,
  title={Quantitative evaluation of software quality},
  author={Boehm, Barry W and Brown, John R and Lipow, Myron},
  booktitle={Proceedings of the 2nd international conference on Software engineering},
  pages={592--605},
  year={1976},
  organization={IEEE Computer Society Press}
}

@article{dorfman1990standards,
  title={Standards, guidelines and examples on system and software requirements engineering},
  author={Dorfman, Merlin and Thayer, Richard H},
  journal={IEEE Computer Society Press Tutorial, Los Alamitos: IEEE Computer Society Press, 1990, edited by Dorfman, Merlin; Thayer, Richard H.},
  volume={1},
  year={1990}
}

@inproceedings{ramesh1993issues,
  title={Issues in the development of a requirements traceability model},
  author={Ramesh, Balasubramaniam and Edwards, Michael},
  booktitle={Requirements Engineering, 1993., Proceedings of IEEE International Symposium on},
  pages={256--259},
  year={1993},
  organization={IEEE}
}

@inproceedings{laurent2007towards,
  title={Towards automated requirements triage},
  author={Laurent, Paula and Cleland-Huang, Jane and Duan, Chuan},
  booktitle={Requirements Engineering Conference, 2007. RE'07. 15th IEEE International},
  pages={131--140},
  year={2007},
  organization={IEEE}
}

@inproceedings{galvao2007survey,
  title={Survey of traceability approaches in model-driven engineering},
  author={Galvao, Ismenia and Goknil, Arda},
  booktitle={Enterprise Distributed Object Computing Conference, 2007. EDOC 2007. 11th IEEE International},
  pages={313--313},
  year={2007},
  organization={IEEE}
}

@ARTICLE{ieee1983srs, 
journal={IEEE Std 830-1984}, 
title={IEEE Guide to Software Requirements Specifications}, 
author={{IEEE}},
year={1984},  
doi={10.1109/IEEESTD.1984.119205}
}

% SCM 2

@article{graves2000predicting,
  title={Predicting fault incidence using software change history},
  author={Graves, Todd L and Karr, Alan F and Marron, James S and Siy, Harvey},
  journal={Software Engineering, IEEE Transactions on},
  volume={26},
  number={7},
  pages={653--661},
  year={2000},
  publisher={IEEE}
}

@inproceedings{herraiz2007towards,
  title={Towards a theoretical model for software growth},
  author={Herraiz, Israel and Gonzalez-Barahona, Jesus M and Robles, Gregorio},
  booktitle={Proceedings of the Fourth International Workshop on Mining Software Repositories},
  pages={21},
  year={2007},
  organization={IEEE Computer Society}
}

@inproceedings{moser2008comparative,
  title={A comparative analysis of the efficiency of change metrics and static code attributes for defect prediction},
  author={Moser, Raimund and Pedrycz, Witold and Succi, Giancarlo},
  booktitle={Software Engineering, 2008. ICSE'08. ACM/IEEE 30th International Conference on},
  pages={181--190},
  year={2008},
  organization={IEEE}
}

% DATA MINING - CLUSTERING

@book{hongbo2010data,
  title={Data Mining Techniques and Applications: An Introduction},
  author={Du, Hongbo},
  year={2010},
  publisher={Course Technology Cengage Learning}
}

@book{rogers2011first,
  title={A first course in machine learning},
  author={Rogers, Simon and Girolami, Mark},
  year={2011},
  publisher={CRC Press}
}

@phdthesis{pilch_diss_pich_2009,
	address = {Konstanz, Germany},
	type = {{PhD} Thesis},
	title = {Applications of Multidimensional Scaling to Graph Drawing},
	url = {http://kops.ub.uni-konstanz.de/handle/urn:nbn:de:bsz:352-opus-83992},
	urldate = {2013-12-18},
	school = {University of Konstanz},
	author = {Pilch, Christian},
	year = {2009}
}

% SCM


@article{kagdi_survey_2007,
	title = {A survey and taxonomy of approaches for mining software repositories in the context of software evolution},
	volume = {19},
	copyright = {Copyright © 2007 John Wiley \& Sons, Ltd.},
	issn = {1532-0618},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/smr.344/abstract},
	doi = {10.1002/smr.344},
	abstract = {A comprehensive literature survey on approaches for mining software repositories ({MSR)} in the context of software evolution is presented. In particular, this survey deals with those investigations that examine multiple versions of software artifacts or other temporal information. A taxonomy is derived from the analysis of this literature and presents the work via four dimensions: the type of software repositories mined (what), the purpose (why), the adopted/invented methodology used (how), and the evaluation method (quality). The taxonomy is demonstrated to be expressive (i.e., capable of representing a wide spectrum of {MSR} investigations) and effective (i.e., facilitates similarities and comparisons of {MSR} investigations). Lastly, a number of open research issues in {MSR} that require further investigation are identified. Copyright © 2007 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {2},
	urldate = {2013-11-08},
	journal = {Journal of Software Maintenance and Evolution: Research and Practice},
	author = {Kagdi, Huzefa and Collard, Michael L. and Maletic, Jonathan I.},
	year = {2007},
	keywords = {mining software repositories, multi-version analysis, Software evolution},
	pages = {77–131},
	file = {Snapshot:/Users/dcutting/Dropbox/PhD/Zotero/storage/CMZ63WZW/full.html:text/html}
},

@article{_empirical_????,
	title = {An Empirical Analysis of the Open Source Development Process Based on Mining of Source Code Repositories},
	lccn = {25075378},
	file = {EBSCO Full Text:/Users/dcutting/Dropbox/PhD/Zotero/storage/ZVRXPQW6/An Empirical Analysis of the Open Source Developme.pdf:application/pdf}
},

@article{scotto_empirical_2007,
	title = {{AN} {EMPIRICAL} {ANALYSIS} {OF} {THE} {OPEN} {SOURCE} {DEVELOPMENT} {PROCESS} {BASED} {ON} {MINING} {OF} {SOURCE} {CODE} {REPOSITORIES}},
	volume = {17},
	issn = {0218-1940, 1793-6403},
	url = {http://www.worldscientific.com/doi/abs/10.1142/S0218194007003215},
	doi = {10.1142/S0218194007003215},
	number = {02},
	urldate = {2013-10-29},
	journal = {International Journal of Software Engineering and Knowledge Engineering},
	author = {Scotto, Marco and Sillitti, Alberto and Succi, Giancarlo},
	month = apr,
	year = {2007},
	pages = {231--247},
	annote = {Pending {ILL} with {UEA} {LIB}},
	file = {AN EMPIRICAL ANALYSIS OF THE OPEN SOURCE DEVELOPMENT PROCESS BASED ON MINING OF SOURCE CODE REPOSITORIES (World Scientific):/Users/dcutting/Dropbox/PhD/Zotero/storage/85SMGV9R/S0218194007003215.html:text/html}
},

@inproceedings{grechanik_empirical_2010,
	address = {New York, {NY}, {USA}},
	series = {{ESEM} '10},
	title = {An empirical investigation into a large-scale Java open source code repository},
	isbn = {978-1-4503-0039-1},
	url = {http://doi.acm.org/10.1145/1852786.1852801},
	doi = {10.1145/1852786.1852801},
	abstract = {Getting insight into different aspects of source code artifacts is increasingly important -- yet there is little empirical research using large bodies of source code, and subsequently there are not much statistically significant evidence of common patterns and facts of how programmers write source code. We pose 32 research questions, explain rationale behind them, and obtain facts from 2,080 randomly chosen Java applications from Sourceforge. Among these facts we find that most methods have one or zero arguments or they do not return any values, few methods are overridden, most inheritance hierarchies have the depth of one, close to 50\% of classes are not explicitly inherited from any classes, and the number of methods is strongly correlated with the number of fields in a class.},
	urldate = {2013-10-29},
	booktitle = {Proceedings of the 2010 {ACM-IEEE} International Symposium on Empirical Software Engineering and Measurement},
	publisher = {{ACM}},
	author = {Grechanik, Mark and {McMillan}, Collin and {DeFerrari}, Luca and Comi, Marco and Crespi, Stefano and Poshyvanyk, Denys and Fu, Chen and Xie, Qing and Ghezzi, Carlo},
	year = {2010},
	keywords = {empirical study, large-scale software, mining software repositories, open source, patterns, practice, software repository},
	pages = {11:1–11:10},
	file = {ACM Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/ATJHAVBI/Grechanik et al. - 2010 - An empirical investigation into a large-scale Java.pdf:application/pdf}
},

@article{williams_automatic_2005,
	title = {Automatic mining of source code repositories to improve bug finding techniques},
	volume = {31},
	issn = {0098-5589},
	doi = {10.1109/TSE.2005.63},
	abstract = {We describe a method to use the source code change history of a software project to drive and help to refine the search for bugs. Based on the data retrieved from the source code repository, we implement a static source code checker that searches for a commonly fixed bug and uses information automatically mined from the source code repository to refine its results. By applying our tool, we have identified a total of 178 warnings that are likely bugs in the Apache Web server source code and a total of 546 warnings that are likely bugs in Wine, an open-source implementation of the Windows {API.} We show that our technique is more effective than the same static analysis that does not use historical data from the source code repository.},
	number = {6},
	journal = {{IEEE} Transactions on Software Engineering},
	author = {Williams, {C.C.} and Hollingsworth, {J.K.}},
	year = {2005},
	keywords = {Apache Web server, application program interfaces, automatic mining, bug finding technique, Computer bugs, configuration control, configuration management, data mining, data retrieval, Debugging, debugging aids, debugging aids., Detectors, file servers, historical data, History, Index Terms- Testing tools, Information retrieval, Inspection, Internet, Open source software, open-source implementation, program debugging, program diagnostics, program testing, Programming profession, public domain software, {SCM} Mining, software project, source code repository, static analysis, static source code checker, testing tools, version control, Web server, Windows {API}},
	pages = {466--480},
	file = {01463230.pdf:/Users/dcutting/Dropbox/PhD/Zotero/storage/EU8Q3UMQ/01463230.pdf:application/pdf}
},

@article{stamelos_code_2002,
	title = {Code quality analysis in open source software development},
	volume = {12},
	issn = {1365-2575},
	url = {http://onlinelibrary.wiley.com/doi/10.1046/j.1365-2575.2002.00117.x/abstract},
	doi = {10.1046/j.1365-2575.2002.00117.x},
	abstract = {Abstract Proponents of open source style software development claim that better software is produced using this model compared with the traditional closed model. However, there is little empirical evidence in support of these claims. In this paper, we present the results of a pilot case study aiming: (a) to understand the implications of structural quality; and (b) to figure out the benefits of structural quality analysis of the code delivered by open source style development. To this end, we have measured quality characteristics of 100 applications written for Linux, using a software measurement tool, and compared the results with the industrial standard that is proposed by the tool. Another target of this case study was to investigate the issue of modularity in open source as this characteristic is being considered crucial by the proponents of open source for this type of software development. We have empirically assessed the relationship between the size of the application components and the delivered quality measured through user satisfaction. We have determined that, up to a certain extent, the average component size of an application is negatively related to the user satisfaction for this application.},
	language = {en},
	number = {1},
	urldate = {2013-10-29},
	journal = {Information Systems Journal},
	author = {Stamelos, Ioannis and Angelis, Lefteris and Oikonomou, Apostolos and Bleris, Georgios L.},
	year = {2002},
	keywords = {Code quality characteristics, open source development, {SCM} Mining, software measurement, structural code analysis, user satisfaction},
	pages = {43–60},
	file = {Snapshot:/Users/dcutting/Dropbox/PhD/Zotero/storage/I7CMH444/full.html:text/html;Stamelos et al. - 2002 - Code quality analysis in open source software deve.pdf:/Users/dcutting/Dropbox/PhD/Zotero/storage/KHEBNC7R/Stamelos et al. - 2002 - Code quality analysis in open source software deve.pdf:application/pdf}
},

@inproceedings{venkataramani_discovery_2013,
	address = {Republic and Canton of Geneva, Switzerland},
	series = {{WWW} '13 Companion},
	title = {Discovery of technical expertise from open source code repositories},
	isbn = {978-1-4503-2038-2},
	url = {http://dl.acm.org/citation.cfm?id=2487788.2487832},
	abstract = {Online Question and Answer websites for developers have emerged as the main forums for interaction during the software development process. The veracity of an answer in such websites is typically verified by the number of 'upvotes' that the answer garners from peer programmers using the same forum. Although this mechanism has proved to be extremely successful in rating the usefulness of the answers, it does not lend itself very elegantly to model the expertise of a user in a particular domain. In this paper, we propose a model to rank the expertise of the developers in a target domain by mining their activity in different opensource projects. To demonstrate the validity of the model, we built a recommendation system for {StackOverflow} which uses the data mined from {GitHub.}},
	urldate = {2013-10-29},
	booktitle = {Proceedings of the 22nd international conference on World Wide Web companion},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Venkataramani, Rahul and Gupta, Atul and Asadullah, Allahbaksh and Muddu, Basavaraju and Bhat, Vasudev},
	year = {2013},
	keywords = {{GitHub}, knowledge discovery, recommendations, source code repository, stackoverflow, technical expertise},
	pages = {97–98},
	file = {ACM Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/KR3TBN4K/Venkataramani et al. - 2013 - Discovery of technical expertise from open source .pdf:application/pdf}
},

@article{spinellis_git_2012,
	title = {Git},
	volume = {29},
	issn = {0740-7459},
	doi = {10.1109/MS.2012.61},
	abstract = {Git is a distributed revision control system available on all mainstream development platforms through a free software license. An important difference of git over its older ancestors is that it elevates the software's revisions to first-class citizens. Developers care deeply about software revisions, and git supports this by giving each developer a complete private copy of the software repository and numerous ways to manage revisions within its context. The ability to associate a local repository with numerous remote ones allows developers and their managers to build a variety of interesting distributed workflows, most of which are impossible to run on a traditional centralized version control system. The local repository also makes git responsive, easy to setup, and able to operate without Internet connectivity. {GitHub} is a git repository hosting provider that simplifies many repository management tasks through a Web-based user interface while also promoting cooperation in open source projects.},
	number = {3},
	journal = {{IEEE} Software},
	author = {Spinellis, D.},
	year = {2012},
	keywords = {configuration management, distributed version control, git, {GitHub}, {SCM} Mining},
	pages = {100--101},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/JCGRMPUW/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/QDUPJ3NT/Spinellis - 2012 - Git.pdf:application/pdf}
},

@inproceedings{caudwell_gource:_2010,
	address = {New York, {NY}, {USA}},
	series = {{SPLASH} '10},
	title = {Gource: visualizing software version control history},
	isbn = {978-1-4503-0240-1},
	shorttitle = {Gource},
	url = {http://doi.acm.org/10.1145/1869542.1869554},
	doi = {10.1145/1869542.1869554},
	abstract = {This film demonstrates a tool for visualizing the development history of software projects as an interactive animation, showing developers working on the hierarchical file-directory structure of a project over the course of its development.},
	urldate = {2013-10-29},
	booktitle = {Proceedings of the {ACM} international conference companion on Object oriented programming systems languages and applications companion},
	publisher = {{ACM}},
	author = {Caudwell, Andrew H.},
	year = {2010},
	keywords = {force-directed, {SCM} Mining, software development history, software visualization},
	pages = {73–74},
	file = {ACM Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/ZTGC96JN/Caudwell - 2010 - Gource visualizing software version control histo.pdf:application/pdf}
},

@inproceedings{hayes_helping_2004,
	title = {Helping analysts trace requirements: an objective look},
	shorttitle = {Helping analysts trace requirements},
	doi = {10.1109/ICRE.2004.1335682},
	abstract = {This work addresses the issues related to improving the overall quality of the requirements tracing process for independent verification and validation analysts. The contribution of the paper is three-fold: we define requirements for a tracing tool based on analyst responsibilities in the tracing process; we introduce several measures for validating that the requirements have been satisfied; and we present a prototype tool that we built, {RETRO} ({REquirements} {TRacing} On-target), to address these requirements. We also present the results of a study used to assess {RETRO's} support of requirements and requirement elements that can be measured objectively.},
	booktitle = {Requirements Engineering Conference, 2004. Proceedings. 12th {IEEE} International},
	author = {Hayes, {J.H.} and Dekhtyar, A. and Sundaram, {S.K.} and Howard, S.},
	year = {2004},
	keywords = {analyst responsibilities, computer aided software engineering, Computer errors, Computer science, formal verification, Humans, independent validation, independent verification, Prototypes, requirements definition, requirements tracing on-target, requirements validation, {RETRO} tool, Risk analysis, Risk management, Spine, System testing, systems analysis, Text analysis, tracing tool},
	pages = {249--259},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/CZX9XAM9/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/5BJBUXJW/Hayes et al. - 2004 - Helping analysts trace requirements an objective .pdf:application/pdf}
},

@inproceedings{hayes_humans_2005,
	address = {New York, {NY}, {USA}},
	series = {{TEFSE} '05},
	title = {Humans in the traceability loop: can't live with 'em, can't live without 'em},
	isbn = {1-59593-243-7},
	shorttitle = {Humans in the traceability loop},
	url = {http://doi.acm.org/10.1145/1107656.1107661},
	doi = {10.1145/1107656.1107661},
	abstract = {The human analyst is required as an active participant in the trace-ability process. Work to date has focused on automated methods that generate traceability information. There is a need for study of what the analysts do with traceability information as well as a study of how they make decisions.},
	urldate = {2013-10-30},
	booktitle = {Proceedings of the 3rd international workshop on Traceability in emerging forms of software engineering},
	publisher = {{ACM}},
	author = {Hayes, Jane Huffman and Dekhtyar, Alex},
	year = {2005},
	keywords = {independent verification and validation, tools, traceability, tracing},
	pages = {20–23},
	file = {ACM Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/82UBHHNI/Hayes and Dekhtyar - 2005 - Humans in the traceability loop can't live with '.pdf:application/pdf}
},

@inproceedings{canfora_identifying_2007,
	title = {Identifying Changed Source Code Lines from Version Repositories.},
	volume = {7},
	url = {http://flossevol.googlecode.com/svn/trunk/papers/10.1.1.98.1923.pdf},
	urldate = {2013-10-29},
	booktitle = {{MSR}},
	author = {Canfora, Gerardo and Cerulo, Luigi and Di Penta, Massimiliano},
	year = {2007},
	pages = {14},
	file = {10.1.1.98.1923.pdf:/Users/dcutting/Dropbox/PhD/Zotero/storage/QE6DEK82/10.1.1.98.1923.pdf:application/pdf}
},

@inproceedings{dekhtyar_make_2007,
	title = {Make the Most of Your Time: How Should the Analyst Work with Automated Traceability Tools?},
	shorttitle = {Make the Most of Your Time},
	doi = {10.1109/PROMISE.2007.8},
	abstract = {Several recent studies employed traditional information retrieval ({IR)} methods to assist in the mapping of elements of software engineering artifacts to each other. This activity is referred to as candidate link generation because the final say in determining the final mapping belongs to the human analyst. Feedback techniques that utilize information from the analyst (on whether the candidate links are correct or not) have been shown to improve the quality of the mappings. Yet the analyst is making an investment of time in providing the feedback. This leads to the question of whether or not guidance can be provided to the analyst on how to best utilize that time. This paper simulates a number of approaches an analyst might take to evaluating the same candidate link list, and discovers that more structured and organized approaches appear to save time/effort of the analyst.},
	booktitle = {International Workshop on Predictor Models in Software Engineering, 2007. {PROMISE'07:} {ICSE} Workshops 2007},
	author = {Dekhtyar, A. and Hayes, {J.H.} and Larsen, J.},
	year = {2007},
	keywords = {Analytical models, automated traceability tools, candidate link generation, Feedback, feedback techniques, Humans, Information retrieval, Performance analysis, Predictive models, Risk management, Software Engineering, software engineering artifacts, software maintenance, software tools, traditional information retrieval methods},
	pages = {4--4},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/E49ENK8K/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/D2HP79ZF/Dekhtyar et al. - 2007 - Make the Most of Your Time How Should the Analyst.pdf:application/pdf}
},

@inproceedings{kagdi_mining_2007,
	title = {Mining software repositories for traceability links},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4268249},
	urldate = {2013-10-29},
	booktitle = {Program Comprehension, 2007. {ICPC'07.} 15th {IEEE} International Conference on},
	author = {Kagdi, Huzefa and Maletic, Jonathan I. and Sharif, Bonita},
	year = {2007},
	pages = {145–154},
	file = {ICPC07-mining.pdf:/Users/dcutting/Dropbox/PhD/Zotero/storage/SHE73ERI/ICPC07-mining.pdf:application/pdf}
},

@inproceedings{allamanis_mining_2013,
	address = {Piscataway, {NJ}, {USA}},
	series = {{MSR} '13},
	title = {Mining source code repositories at massive scale using language modeling},
	isbn = {978-1-4673-2936-1},
	url = {http://dl.acm.org/citation.cfm?id=2487085.2487127},
	abstract = {The tens of thousands of high-quality open source software projects on the Internet raise the exciting possibility of studying software development by finding patterns across truly large source code repositories. This could enable new tools for developing code, encouraging reuse, and navigating large projects. In this paper, we build the first giga-token probabilistic language model of source code, based on 352 million lines of Java. This is 100 times the scale of the pioneering work by Hindle et al. The giga-token model is significantly better at the code suggestion task than previous models. More broadly, our approach provides a new "lens" for analyzing software projects, enabling new complexity metrics based on statistical analysis of large corpora. We call these metrics data-driven complexity metrics. We propose new metrics that measure the complexity of a code module and the topical centrality of a module to a software project. In particular, it is possible to distinguish reusable utility classes from classes that are part of a program's core logic based solely on general information theoretic criteria.},
	urldate = {2013-10-29},
	booktitle = {Proceedings of the 10th Working Conference on Mining Software Repositories},
	publisher = {{IEEE} Press},
	author = {Allamanis, Miltiadis and Sutton, Charles},
	year = {2013},
	pages = {207–216},
	file = {ACM Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/4S2T5N8H/Allamanis and Sutton - 2013 - Mining source code repositories at massive scale u.pdf:application/pdf}
},

@inproceedings{dyer_mining_2013,
	address = {New York, {NY}, {USA}},
	series = {{SPLASH} '13},
	title = {Mining source code repositories with boa},
	isbn = {978-1-4503-1995-9},
	url = {http://doi.acm.org/10.1145/2508075.2514570},
	doi = {10.1145/2508075.2514570},
	abstract = {Mining source code has become a common task for researchers and yielded significant benefits for the software engineering community. Mining source code however is a very difficult and time consuming task. The Boa language and infrastructure was designed to ease mining of project and revision metadata. Recently Boa was extended to support mining source code and currently contains source code for over 23k Java projects, including full revision histories. In this demonstration we pose source code mining tasks and give solutions using Boa. We then execute these programs via our web-based infrastructure and show how to easily make the results available for future researchers.},
	urldate = {2013-10-29},
	booktitle = {Proceedings of the 2013 companion publication for conference on Systems, programming, \&\#38; applications: software for humanity},
	publisher = {{ACM}},
	author = {Dyer, Robert and Nguyen, Hoan Anh and Rajan, Hridesh and Nguyen, Tien N.},
	year = {2013},
	keywords = {mapreduce, Software repository mining},
	pages = {13–14},
	file = {ACM Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/QGG7JWKB/Dyer et al. - 2013 - Mining source code repositories with boa.pdf:application/pdf}
},

@inproceedings{gethers_integrating_2011,
	title = {On integrating orthogonal information retrieval methods to improve traceability recovery},
	doi = {10.1109/ICSM.2011.6080780},
	abstract = {Different Information Retrieval ({IR)} methods have been proposed to recover traceability links among software artifacts. Until now there is no single method that sensibly outperforms the others, however, it has been empirically shown that some methods recover different, yet complementary traceability links. In this paper, we exploit this empirical finding and propose an integrated approach to combine orthogonal {IR} techniques, which have been statistically shown to produce dissimilar results. Our approach combines the following {IR-based} methods: Vector Space Model ({VSM)}, probabilistic Jensen and Shannon ({JS)} model, and Relational Topic Modeling ({RTM)}, which has not been used in the context of traceability link recovery before. The empirical case study conducted on six software systems indicates that the integrated method outperforms stand-alone {IR} methods as well as any other combination of non-orthogonal methods with a statistically significant margin.},
	booktitle = {2011 27th {IEEE} International Conference on Software Maintenance ({ICSM)}},
	author = {Gethers, M. and Oliveto, R. and Poshyvanyk, D. and Lucia, {A.D.}},
	year = {2011},
	keywords = {Accuracy, complementary traceability links, Information retrieval, Measurement, orthogonal information retrieval, probabilistic Jensen and Shannon model, probability, relational topic modeling, {RTM}, software artifacts, Software Engineering, traceability recovery, Unified modeling language, vector space model, Vocabulary, {VSM}},
	pages = {133--142},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/QAE6W7A7/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/KXVXCJ6K/Gethers et al. - 2011 - On integrating orthogonal information retrieval me.pdf:application/pdf}
},

@article{ying_predicting_2004,
	title = {Predicting source code changes by mining change history},
	volume = {30},
	issn = {0098-5589},
	doi = {10.1109/TSE.2004.52},
	abstract = {Software developers are often faced with modification tasks that involve source which is spread across a code base. Some dependencies between source code, such as those between source code written in different languages, are difficult to determine using existing static and dynamic analyses. To augment existing analyses and to help developers identify relevant source code during a modification task, we have developed an approach that applies data mining techniques to determine change patterns - sets of files that were changed together frequently in the past - from the change history of the code base. Our hypothesis is that the change patterns can be used to recommend potentially relevant source code to a developer performing a modification task. We show that this approach can reveal valuable dependencies by applying the approach to the Eclipse and Mozilla open source projects and by evaluating the predictability and interestingness of the recommendations produced for actual modification tasks on these systems.},
	number = {9},
	journal = {{IEEE} Transactions on Software Engineering},
	author = {Ying, {A.T.T.} and Murphy, {G.C.} and Ng, R. and Chu-Carroll, {M.C.}},
	year = {2004},
	keywords = {65, association rules, change history, classification, clustering, code base, Computer languages, Computer science, Computer Society, configuration management, data mining, data mining technique, data mining., Eclipse open source project, Frequency, History, Index Terms- Enhancement, maintainability, modification task, Mozilla open source project, Pattern analysis, pattern classification, pattern clustering, program verification, Programming profession, {SCM} Mining, software developers, software maintainability, software maintenance, Software systems, software tools, source code changes prediction},
	pages = {574--586},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/VBV4GCAG/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/MJUDFWRU/Ying et al. - 2004 - Predicting source code changes by mining change hi.pdf:application/pdf}
},

@inproceedings{marcus_recovering_2003,
	title = {Recovering documentation-to-source-code traceability links using latent semantic indexing},
	doi = {10.1109/ICSE.2003.1201194},
	abstract = {An information retrieval technique, latent semantic indexing, is used to automatically identify traceability links from system documentation to program source code. The results of two experiments to identify links in existing software systems (i.e., the {LEDA} library, and Albergate) are presented. These results are compared with other similar type experimental results of traceability link identification using different types of information retrieval techniques. The method presented proves to give good results by comparison and additionally it is a low cost, highly flexible method to apply with regards to preprocessing and/or parsing of the source code and documentation.},
	booktitle = {25th International Conference on Software Engineering, 2003. Proceedings},
	author = {Marcus, A. and Maletic, {J.I.}},
	year = {2003},
	keywords = {computer aided software engineering, Computer science, Costs, Documentation, Indexing, Information analysis, Information retrieval, information retrieval technique, latent semantic indexing, natural languages, program source code, Software Engineering, Software libraries, Software systems, system documentation, traceability link identification},
	pages = {125--135},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/EQNTESIZ/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/RTW7WFVE/Marcus and Maletic - 2003 - Recovering documentation-to-source-code traceabili.pdf:application/pdf}
},

@article{antoniol_recovering_2002,
	title = {Recovering traceability links between code and documentation},
	volume = {28},
	issn = {0098-5589},
	doi = {10.1109/TSE.2002.1041053},
	abstract = {Software system documentation is almost always expressed informally in natural language and free text. Examples include requirement specifications, design documents, manual pages, system development journals, error logs, and related maintenance reports. We propose a method based on information retrieval to recover traceability links between source code and free text documents. A premise of our work is that programmers use meaningful names for program items, such as functions, variables, types, classes, and methods. We believe that the application-domain knowledge that programmers process when writing the code is often captured by the mnemonics for identifiers; therefore, the analysis of these mnemonics can help to associate high-level concepts with program concepts and vice-versa. We apply both a probabilistic and a vector space information retrieval model in two case studies to trace C++ source code onto manual pages and Java code to functional requirements. We compare the results of applying the two models, discuss the benefits and limitations, and describe directions for improvements.},
	number = {10},
	journal = {{IEEE} Transactions on Software Engineering},
	author = {Antoniol, G. and Canfora, G. and Casazza, G. and De Lucia, A. and Merlo, E.},
	year = {2002},
	keywords = {Context modeling, Documentation, free text documents, Information resources, Information retrieval, Inspection, Java, Mathematics, natural languages, object orientation, object-oriented programming, probability, program comprehension, Programming profession, software system documentation, source code, system documentation, traceability, traceability link recovery, vector space, Writing},
	pages = {970--983},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/5NUEFQZQ/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/9Q4WSBRE/Antoniol et al. - 2002 - Recovering traceability links between code and doc.pdf:application/pdf}
},

@inproceedings{corley_recovering_2011,
	address = {New York, {NY}, {USA}},
	series = {{TEFSE} '11},
	title = {Recovering traceability links between source code and fixed bugs via patch analysis},
	isbn = {978-1-4503-0589-1},
	url = {http://doi.acm.org/10.1145/1987856.1987863},
	doi = {10.1145/1987856.1987863},
	abstract = {Traceability links can be recovered using data mined from a revision control system, such as {CVS}, and an issue tracking system, such as Bugzilla. Existing approaches to recover links between a bug and the methods changed to fix the bug rely on the presence of the bug's identifier in a {CVS} log message. In this paper we present an approach that relies instead on the presence of a patch in the issue report for the bug. That is, rather than analyzing deltas retrieved from {CVS} to recover links, our approach analyzes patches retrieved from Bugzilla. We use {BugTrace}, the tool implementing our approach, to conduct a case study in which we compare the links recovered by our approach to links recovered by manual inspection. The results of the case study support the efficacy of our approach. After describing the limitations of our case study, we conclude by reviewing closely related work and suggesting possible future work.},
	urldate = {2013-10-30},
	booktitle = {Proceedings of the 6th International Workshop on Traceability in Emerging Forms of Software Engineering},
	publisher = {{ACM}},
	author = {Corley, Christopher S. and Kraft, Nicholas A. and Etzkorn, Letha H. and Lukins, Stacy K.},
	year = {2011},
	keywords = {bug assignment, bug mapping, link recovery, mining software repositories, trace automation, traceability},
	pages = {31–37},
	file = {ACM Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/MDH362NN/Corley et al. - 2011 - Recovering traceability links between source code .pdf:application/pdf}
},

@article{hayes_requirements_2007,
	title = {{REquirements} {TRacing} On target ({RETRO):} improving software maintenance through traceability recovery},
	volume = {3},
	issn = {1614-5046, 1614-5054},
	shorttitle = {{REquirements} {TRacing} On target ({RETRO)}},
	url = {http://link.springer.com/article/10.1007/s11334-007-0024-1},
	doi = {10.1007/s11334-007-0024-1},
	abstract = {A number of important tasks in software maintenance require an up-to-date requirements traceability matrix ({RTM):} change impact analysis, determination of test cases to execute for regression testing, etc. The generation and maintenance of {RTMs} are tedious and error-prone, and they are hence often not done. In this paper, we present {REquirements} {TRacing} On-target ({RETRO)}, a special- purpose requirements tracing tool. We discuss how {RETRO} automates the generation of {RTMs} and present the results of a study comparing manual {RTM} generation to {RTM} generation using {RETRO.} The study showed that {RETRO} found significantly more correct links than manual tracing and took only one third of the time to do so.},
	language = {en},
	number = {3},
	urldate = {2013-10-30},
	journal = {Innovations in Systems and Software Engineering},
	author = {Hayes, Jane Huffman and Dekhtyar, Alex and Sundaram, Senthil Karthikeyan and Holbrook, E. Ashlee and Vadlamudi, Sravanthi and April, Alain},
	month = sep,
	year = {2007},
	keywords = {Computer Applications, Computing Methodologies, Software Engineering},
	pages = {193--202},
	file = {Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/9AAZRIWX/Hayes et al. - 2007 - REquirements TRacing On target (RETRO) improving .pdf:application/pdf;Snapshot:/Users/dcutting/Dropbox/PhD/Zotero/storage/KMIIFMCM/s11334-007-0024-1.html:text/html}
},

@article{ohba_software_1984,
	title = {Software reliability analysis models},
	volume = {28},
	issn = {0018-8646},
	doi = {10.1147/rd.284.0428},
	abstract = {This paper discusses improvements to conventional software reliability analysis models by making the assumptions on which they are based more realistic. In an actual project environment, sometimes no more information is available than reliability data obtained from a test report. The models described here are designed to resolve the problems caused by this constraint on the availability of reliability data. By utilizing the technical knowledge about a program, a test, and test data, we can select an appropriate software reliability analysis model for accurate quality assessment. The delayed S-shaped growth model, the inflection S-shaped model, and the hyperexponential model are proposed.},
	number = {4},
	journal = {{IBM} Journal of Research and Development},
	author = {Ohba, Mitsuru},
	year = {1984},
	keywords = {{SCM} Mining},
	pages = {428--443},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/TEBFJ98V/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/IETSGC2G/Ohba - 1984 - Software reliability analysis models.pdf:application/pdf}
},

@inproceedings{kagdi_software_2007,
	title = {Software repositories: A source for traceability links},
	shorttitle = {Software repositories},
	url = {http://www.cs.kent.edu/~jmaletic/papers/TEFSE07-kagdi.pdf},
	urldate = {2013-10-29},
	booktitle = {Proceedings of 4th {ACM} International Workshop on Traceability in Emerging Forms of Software Engineering ({GCT/TEFSE’07)}, Lexington, {KY}, {USA}},
	author = {Kagdi, Huzefa and Maletic, Jonathan I.},
	year = {2007},
	pages = {32–39},
	file = {TEFSE07-kagdi.pdf:/Users/dcutting/Dropbox/PhD/Zotero/storage/V5P53FBH/TEFSE07-kagdi.pdf:application/pdf}
},

@inproceedings{ying_source_2005,
	address = {New York, {NY}, {USA}},
	series = {{MSR} '05},
	title = {Source code that talks: an exploration of Eclipse task comments and their implication to repository mining},
	isbn = {1-59593-123-6},
	shorttitle = {Source code that talks},
	url = {http://doi.acm.org/10.1145/1082983.1083152},
	doi = {10.1145/1082983.1083152},
	abstract = {A programmer performing a change task to a system can benefit from accurate comments on the source code. As part of good programming practice described by Kernighan and Pike in the book The Practice of Programming, comments should "aid the understanding of a program by briefly pointing out salient details or by providing a larger-scale view of the proceedings." In this paper, we explore the widely varying uses of comments in source code. We find that programmers not only use comments for describing the actual source code, but also use comments for many other purposes, such as "talking" to colleagues through the source code using a comment {"Joan}, please fix this method." This kind of comments can complicate the mining of project information because such team communication is often perceived to reside in separate archives, such as emails or newsgroup postings, rather than in the source code. Nevertheless, these and other types of comments can be very useful inputs for mining project information.},
	urldate = {2013-10-29},
	booktitle = {Proceedings of the 2005 international workshop on Mining software repositories},
	publisher = {{ACM}},
	author = {Ying, Annie T. T. and Wright, James L. and Abrams, Steven},
	year = {2005},
	pages = {1–5},
	file = {ACM Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/64VJ6AHV/Ying et al. - 2005 - Source code that talks an exploration of Eclipse .pdf:application/pdf}
},

@article{zaidman_studying_2011,
	title = {Studying the co-evolution of production and test code in open source and industrial developer test processes through repository mining},
	volume = {16},
	issn = {1382-3256, 1573-7616},
	url = {http://link.springer.com/article/10.1007/s10664-010-9143-7},
	doi = {10.1007/s10664-010-9143-7},
	abstract = {Many software production processes advocate rigorous development testing alongside functional code writing, which implies that both test code and production code should co-evolve. To gain insight in the nature of this co-evolution, this paper proposes three views (realized by a tool called {TeMo)} that combine information from a software project’s versioning system, the size of the various artifacts and the test coverage reports. We validate these views against two open source and one industrial software project and evaluate our results both with the help of log messages, code inspections and the original developers of the software system. With these views we could recognize different co-evolution scenarios (i.e., synchronous and phased) and make relevant observations for both developers as well as test engineers.},
	language = {en},
	number = {3},
	urldate = {2013-10-29},
	journal = {Empirical Software Engineering},
	author = {Zaidman, Andy and Rompaey, Bart Van and Deursen, Arie van and Demeyer, Serge},
	month = jun,
	year = {2011},
	keywords = {Co-evolution, Programming Languages, Compilers, Interpreters, Software {Engineering/Programming} and Operating Systems, Software evolution, Software repository mining, Software testing, Test coverage},
	pages = {325--364},
	file = {Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/XR9XRH92/Zaidman et al. - 2011 - Studying the co-evolution of production and test c.pdf:application/pdf;Snapshot:/Users/dcutting/Dropbox/PhD/Zotero/storage/WUVK8E9G/10.html:text/html}
},

@inproceedings{maletic_supporting_2004,
	title = {Supporting source code difference analysis},
	doi = {10.1109/ICSM.2004.1357805},
	abstract = {The paper describes an approach to easily conduct analysis of source-code differences. The approach is termed meta-differencing to reflect the fact that additional knowledge of the differences can be automatically derived. Meta-differencing is supported by an underlying source-code representation developed by the authors. The representation, {srcML}, is an {XML} format that explicitly embeds abstract syntax within the source code while preserving the documentary structure as dictated by the developer. {XML} tools are leveraged together with standard differencing utilities (i.e., diff,) to generate a meta-difference. The meta-difference is also represented in an {XML} format called {srcDiff.} The meta-difference contains specific syntactic information regarding the source-code changes. In turn this can be queried and searched with {XML} tools for the purpose of extracting information about the specifics of the changes. A case study of using the meta-differencing approach on an open-source system is presented to demonstrate its usefulness and validity.},
	booktitle = {20th {IEEE} International Conference on Software Maintenance, 2004. Proceedings},
	author = {Maletic, {J.I.} and Collard, {M.L.}},
	year = {2004},
	keywords = {abstract syntax, Code standards, Computer science, data flow analysis, data mining, documentary structure, History, Information analysis, meta-differencing, Open source software, open-source system, public domain software, {SCM} Mining, software maintenance, source code difference analysis, source-code representation, {srcDiff}, {srcML}, Tree graphs, {XML}, {XML} format, {XML} tool},
	pages = {210--219},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/2ADXSR3H/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/6WGK3Q2V/Maletic and Collard - 2004 - Supporting source code difference analysis.pdf:application/pdf}
},

@inproceedings{bird_promises_2009,
	title = {The promises and perils of mining git},
	doi = {10.1109/MSR.2009.5069475},
	abstract = {We are now witnessing the rapid growth of decentralized source code management ({DSCM)} systems, in which every developer has her own repository. {DSCMs} facilitate a style of collaboration in which work output can flow sideways (and privately) between collaborators, rather than always up and down (and publicly) via a central repository. Decentralization comes with both the promise of new data and the peril of its misinterpretation. We focus on git, a very popular {DSCM} used in high-profile projects. Decentralization, and other features of git, such as automatically recorded contributor attribution, lead to richer content histories, giving rise to new questions such as {ldquoHow} do contributions flow between developers to the official project repository?rdquo However, there are pitfalls. Commits may be reordered, deleted, or edited as they move between repositories. The semantics of terms common to {SCMs} and {DSCMs} sometimes differ markedly, potentially creating confusion. For example, a commit is immediately visible to all developers in centralized {SCMs}, but not in {DSCMs.} Our goal is to help researchers interested in {DSCMs} avoid these and other perils when mining and analyzing git data.},
	booktitle = {6th {IEEE} International Working Conference on Mining Software Repositories, 2009. {MSR} '09},
	author = {Bird, C. and Rigby, {P.C.} and Barr, {E.T.} and Hamilton, {D.J.} and German, {D.M.} and Devanbu, P.},
	year = {2009},
	keywords = {automatically recorded contributor attribution, Birds, central repository, collaboration, Collaborative work, data analysis, data mining, decentralization, decentralized source code management systems, groupware, History, Kernel, Linux, Mercury (metals), mining git, Open source software, Packaging, Rails, {SCM} Mining},
	pages = {1--10},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/DEKHM2JB/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/2F8J5A6R/Bird et al. - 2009 - The promises and perils of mining git.pdf:application/pdf}
},

@inproceedings{hassan_road_2008,
	title = {The road ahead for mining software repositories},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4659248},
	urldate = {2013-10-29},
	booktitle = {Frontiers of Software Maintenance, 2008. {FoSM} 2008.},
	author = {Hassan, Ahmed E.},
	year = {2008},
	pages = {48–57},
	file = {The road ahead for mining software repositories.pdf:/Users/dcutting/Dropbox/PhD/Zotero/storage/JQQDH8IZ/The road ahead for mining software repositories.pdf:application/pdf}
},

@article{purushothaman_toward_2005,
	title = {Toward understanding the rhetoric of small source code changes},
	volume = {31},
	issn = {0098-5589},
	doi = {10.1109/TSE.2005.74},
	abstract = {Understanding the impact of software changes has been a challenge since software systems were first developed. With the increasing size and complexity of systems, this problem has become more difficult. There are many ways to identify the impact of changes on the system from the plethora of software artifacts produced during development, maintenance, and evolution. We present the analysis of the software development process using change and defect history data. Specifically, we address the problem of small changes by focusing on the properties of the changes rather than the properties of the code itself. Our study reveals that 1) there is less than 4 percent probability that a one-line change introduces a fault in the code, 2) nearly 10 percent of all changes made during the maintenance of the software under consideration were one-line changes, 3) nearly 50 percent of the changes were small changes, 4) nearly 40 percent of changes to fix faults resulted in further faults, 5) the phenomena of change differs for additions, deletions, and modifications as well as for the number of lines affected, and 6) deletions of up to 10 lines did not cause faults.},
	number = {6},
	journal = {{IEEE} Transactions on Software Engineering},
	author = {Purushothaman, R. and Perry, {D.E.}},
	year = {2005},
	keywords = {Computer architecture, Computer Society, Costs, defect history data, fault probabilities, fault probabilities., History, Index Terms- Source code changes, Life testing, one-line changes, plethora, Programming, reverse engineering, Rhetoric, Risk management, {SCM} Mining, software artifacts, software development process, software fault tolerance, software faults, software maintenance, software system, Software systems, source code changes},
	pages = {511--526},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/JFVSRTS7/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/G4N8AVQW/Purushothaman and Perry - 2005 - Toward understanding the rhetoric of small source .pdf:application/pdf}
},

@article{kagdi_towards_2005,
	title = {Towards a taxonomy of approaches for mining of source code repositories},
	volume = {30},
	issn = {0163-5948},
	url = {http://doi.acm.org/10.1145/1082983.1083159},
	doi = {10.1145/1082983.1083159},
	abstract = {Source code version repositories provide a treasure of information encompassing the changes introduced in the system throughout its evolution. These repositories are typically managed by tools such as {CVS.} However, these tools identify and express changes in terms of physical attributes i.e., file and line numbers. Recently, to help support the mining of software repositories ({MSR)}, researchers have proposed methods to derive and express changes from source code repositories in a more source-code "aware" manner (i.e., syntax and semantic). Here, we discuss these {MSR} techniques in light of what changes are identified, how they are expressed, the adopted methodology, evaluation, and results. This work forms the basis for a taxonomic description of {MSR} approaches.},
	number = {4},
	urldate = {2013-10-29},
	journal = {{SIGSOFT} Softw. Eng. Notes},
	author = {Kagdi, Huzefa and Collard, Michael L. and Maletic, Jonathan I.},
	month = may,
	year = {2005},
	keywords = {mining software repositories, survey, taxonomy},
	pages = {1–5},
	file = {ACM Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/VGPWFVGZ/Kagdi et al. - 2005 - Towards a taxonomy of approaches for mining of sou.pdf:application/pdf}
},

@inproceedings{asun_ion_towards_2008,
	address = {New York, {NY}, {USA}},
	series = {{ICSE} Companion '08},
	title = {Towards practical software traceability},
	isbn = {978-1-60558-079-1},
	url = {http://doi.acm.org/10.1145/1370175.1370228},
	doi = {10.1145/1370175.1370228},
	abstract = {The importance of software traceability to software development is recognized by researchers and practitioners; yet, current approaches fall short of providing effective traceability in practice. An analysis of reported difficulties with traceability reveals that interacting factors from the economic, technical, and social perspectives hinder traceability. Motivated by the multi-faceted traceability problem, we combine architecture-centric stakeholder-driven traceability with open hypermedia, and we use insights from e-Science to guide our approach. We highlight expected contributions and discuss evaluation plans. Finally, we distinguish our approach from related research and technologies.},
	urldate = {2013-10-30},
	booktitle = {Companion of the 30th international conference on Software engineering},
	publisher = {{ACM}},
	author = {Asun ion, Hazeline U.},
	year = {2008},
	keywords = {architecture-centric traceability, open hypermedia, software traceability, stakeholder-driven traceability},
	pages = {1023–1026},
	file = {ACM Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/AM9CD3IN/Asun ion - 2008 - Towards practical software traceability.pdf:application/pdf}
},

@inproceedings{maletic_tql:_2009,
	title = {{TQL:} A query language to support traceability},
	shorttitle = {{TQL}},
	doi = {10.1109/TEFSE.2009.5069577},
	abstract = {A query language for traceability is proposed and presented. The language, {TQL}, is based in {XML} and supports queries across multiple artifacts and multiple traceability link types. A number of primitives are defined to allow complex queries to be constructed and executed. Example queries are presented in the context of traceability questions. The technical details of the language and issues of implementation are discussed.},
	booktitle = {{ICSE} Workshop on Traceability in Emerging Forms of Software Engineering, 2009. {TEFSE} '09},
	author = {Maletic, {J.I.} and Collard, {M.L.}},
	year = {2009},
	keywords = {Conferences, Database languages, Joining processes, Kernel, Linux, multiple traceability link type, program diagnostics, query languages, Safety, software artifact, Testing, trace query language, {XML}},
	pages = {16--20},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/FXG8ZWIE/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/FTKUI67X/Maletic and Collard - 2009 - TQL A query language to support traceability.pdf:application/pdf}
},

@inproceedings{ali_trust-based_2011,
	title = {Trust-Based Requirements Traceability},
	doi = {10.1109/ICPC.2011.42},
	abstract = {Information retrieval ({IR)} approaches have proven useful in recovering traceability links between free text documentation and source code. {IR-based} traceability recovery approaches produce ranked lists of traceability links between pieces of documentation and source code. These traceability links are then pruned using various strategies and, finally, validated by human experts. In this paper we propose two contributions to improve the precision and recall of traceability links and, thus, reduces the required human experts' manual validation effort. First, we propose a novel approach, Trustrace, inspired by Web trust models to improve the precision and recall of traceability links: Trustrace uses any traceability recovery approach to obtain a set of traceability links, which rankings are then re-evaluated using a set of other traceability recovery approaches. Second, we propose a novel traceability recovery approach, Histrace, to identify traceability links between requirements and source code through {CVS/SVN} change logs using a Vector Space Model ({VSM).} We combine a traditional recovery traceability approach with Histrace to build {TrustraceVSM}, Histrace in which we use Histrace as one expert adding knowledge to the traceability links extracted from {CVS/SVN} change logs. We apply {TrustraceVSM}, Histrace on two case studies to compare its traceability links with those recovered using only the {VSM-based} approach, in terms of precision and recall. We show that {TrustraceVSM}, Histrace improves with statistical significance the precision of the traceability links while also improving recall but without statistical significance.},
	booktitle = {2011 {IEEE} 19th International Conference on Program Comprehension ({ICPC)}},
	author = {Ali, N. and Gueheneuc, Y. and Antoniol, G.},
	year = {2011},
	keywords = {Documentation, Electronic mail, experts, Indexing, Information retrieval, information retrieval approach, {IR-based} traceability recovery approach, Probabilistic logic, requirements, security of data, Semantics, Software, source code, traceability, traceability link, trust-based model, trust-based requirements traceability, Trustrace approach, vector space model, Web sites},
	pages = {111--120},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/QBT3SHBQ/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/7HQSB5CS/Ali et al. - 2011 - Trust-Based Requirements Traceability.pdf:application/pdf}
},

@article{ali_trustrace:_2013,
	title = {Trustrace: Mining Software Repositories to Improve the Accuracy of Requirement Traceability Links},
	volume = {39},
	issn = {0098-5589, 1939-3520},
	shorttitle = {Trustrace},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6341764},
	doi = {10.1109/TSE.2012.71},
	number = {5},
	urldate = {2013-10-30},
	journal = {{IEEE} Transactions on Software Engineering},
	author = {Ali, Nasir and Gueheneuc, Yann-Gael and Antoniol, Giuliano},
	month = may,
	year = {2013},
	pages = {725--741},
	file = {Mining_Software_Repositories_Requirement_Traceability.pdf:/Users/dcutting/Dropbox/PhD/Zotero/storage/5RNPADQA/Mining_Software_Repositories_Requirement_Traceability.pdf:application/pdf}
},

@article{bock_uml_2003,
	title = {{UML} without pictures},
	volume = {20},
	issn = {0740-7459},
	doi = {10.1109/MS.2003.1231148},
	abstract = {This article reviews the concepts of repository-centered development with {UML}, explaining how notation, semantics, and model compilation relate. {UML} can be used in many formats, including presented as text, parsed into a standardized repository, and compiled to multiple programming languages. The example given uses the {UML} 2 repository.},
	number = {5},
	journal = {{IEEE} Software},
	author = {Bock, C.},
	year = {2003},
	keywords = {model compilation, notation, program compilers, programming language semantics, programming languages, repository-centered architecture, repository-centered development, Semantics, specification languages, {UML}, {UML} 2 repository, Unified modeling language},
	pages = {33--35},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/T5R8HCIE/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/TKSWPKTD/Bock - 2003 - UML without pictures.pdf:application/pdf}
},

@inproceedings{valetto_using_2007,
	title = {Using Software Repositories to Investigate Socio-technical Congruence in Development Projects},
	doi = {10.1109/MSR.2007.33},
	abstract = {We propose a quantitative measure of socio- technical congruence as an indicator of the performance of an organization in carrying out a software development project. We show how the information necessary to implement that measure can be mined from commonly used software repositories, and we describe how socio-technical congruence can be computed based on that information.},
	booktitle = {Fourth International Workshop on Mining Software Repositories, 2007. {ICSE} Workshops {MSR} '07},
	author = {Valetto, G. and Helander, M. and Ehrlich, Kate and Chulani, Sunita and Wegman, M. and Williams, C.},
	year = {2007},
	keywords = {Collaborative software, Frequency, Observability, Online {Communities/Technical} Collaboration, organization performance indicator, Productivity, Programming, project management, Social network services, socio-economic effects, socio-technical congruence, software development management, software development project, software measurement, Software quality, software repository},
	pages = {25--25},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/K5SMWB4G/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/7F8DZFCN/Valetto et al. - 2007 - Using Software Repositories to Investigate Socio-t.pdf:application/pdf}
},

@inproceedings{kouters_whos_2012,
	title = {Who's who in Gnome: Using {LSA} to merge software repository identities},
	shorttitle = {Who's who in Gnome},
	doi = {10.1109/ICSM.2012.6405329},
	abstract = {Understanding an individual's contribution to an ecosystem often necessitates integrating information from multiple repositories corresponding to different projects within the ecosystem or different kinds of repositories (e.g., mail archives and version control systems). However, recognising that different contributions belong to the same contributor is challenging, since developers may use different aliases. It is known that existing identity merging algorithms are sensitive to large discrepancies between the aliases used by the same individual: the noisier the data, the worse their performance. To assess the scale of the problem for a large software ecosystem, we study all Gnome Git repositories, classify the differences in aliases, and discuss robustness of existing algorithms with respect to these types of differences. We then propose a new identity merging algorithm based on Latent Semantic Analysis ({LSA)}, designed to be robust against more types of differences in aliases, and evaluate it empirically by means of cross-validation on Gnome Git authors. Our results show a clear improvement over existing algorithms in terms of precision and recall on worst-case input data.},
	booktitle = {2012 28th {IEEE} International Conference on Software Maintenance ({ICSM)}},
	author = {Kouters, E. and Vasilescu, B. and Serebrenik, A. and van den Brand, {M.G.J.}},
	year = {2012},
	keywords = {Algorithm design and analysis, alias classification, Birds, Classification algorithms, configuration management, cross-validation, data integration, data noise, Electronic mail, empirical evaluation, Gnome, {GNOME} Git repositories, identity merging, information integration, latent semantic analysis, {LSA}, mail archives, Merging, pattern classification, precision value, public domain software, recall value, Robustness, {SCM} Mining, Software, software ecosystem, software maintenance, software repository identity merging algorithm, version control systems, worst-case input data},
	pages = {592--595},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/MG3CMERG/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/H6HXVU8Z/Kouters et al. - 2012 - Who's who in Gnome Using LSA to merge software re.pdf:application/pdf}
}

% SCM COCOMM

@inproceedings{bieman2003understanding,
  title={Understanding change-proneness in OO software through visualization},
  author={Bieman, James M and Andrews, Anneliese Amschler and Yang, Helen J},
  booktitle={Program Comprehension, 2003. 11th IEEE International Workshop on},
  pages={44--53},
  year={2003},
  organization={IEEE}
}


@inproceedings{beyer_animated_2006,
	title = {Animated Visualization of Software History using Evolution Storyboards},
	doi = {10.1109/WCRE.2006.14},
	abstract = {The understanding of the structure of a software system can be improved by analyzing the system's evolution during development. Visualizations of software history that provide only static views do not capture the dynamic nature of software evolution. We present a new visualization technique, the Evolution Storyboard, which provides dynamic views of the evolution of a software's structure. An evolution storyboard consists of a sequence of animated panels, which highlight the structural changes in the system; one panel for each considered time period. Using storyboards, engineers can spot good design, signs of structural decay, or the spread of cross cutting concerns in the code. We implemented our concepts in a tool, which automatically extracts software dependency graphs from version control repositories and computes storyboards based on panels for different time periods. For applying our approach in practice, we provide a step by step guide that others can follow along the storyboard visualizations, in order to study the evolution of large systems. We have applied our method to several large open source software systems. In this paper, we demonstrate that our method provides additional information (compared to static views) on the {ArgoUML} project, an open source {UML} modeling tool},
	booktitle = {13th Working Conference on Reverse Engineering, 2006. {WCRE} '06},
	author = {Beyer, D. and Hassan, {A.E.}},
	year = {2006},
	keywords = {animated visualization, Animation, {ArgoUML} project, Automatic control, computer animation, data mining, data visualisation, Design engineering, evolution storyboards, graph theory, History, Motion pictures, open source software systems, program diagnostics, software dependency graphs, Software Engineering, Software evolution, software history, software reviews, software structure, software system, Software systems, software tools, storyboard visualizations, {UML} modeling tool, Unified modeling language, version control repository, Visualization, visualization technique},
	pages = {199--210},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/Z5T7U2EJ/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/SE6473C9/Beyer and Hassan - 2006 - Animated Visualization of Software History using E.pdf:application/pdf}
},

@article{lung_applications_2004,
	title = {Applications of clustering techniques to software partitioning, recovery and restructuring},
	volume = {73},
	issn = {0164-1212},
	url = {http://www.sciencedirect.com/science/article/pii/S0164121203002346},
	doi = {10.1016/S0164-1212(03)00234-6},
	abstract = {The artifacts constituting a software system are sometimes unnecessarily coupled with one another or may drift over time. As a result, support of software partitioning, recovery, and restructuring is often necessary. This paper presents studies on applying the numerical taxonomy clustering technique to software applications. The objective is to facilitate those activities just mentioned and to improve design, evaluation and evolution. Numerical taxonomy is mathematically simple and yet it is a useful mechanism for component clustering and software partitioning. The technique can be applied at various levels of abstraction or to different software life-cycle phases. We have applied the technique to: (1) software partitioning at the software architecture design phase; (2) grouping of components based on the source code to recover the software architecture in the reverse engineering process; (3) restructuring of a software to support evolution in the maintenance stage; and (4) improving cohesion and reducing coupling for source code. In this paper, we provide an introduction to the numerical taxonomy, discuss our experiences in applying the approach to various areas, and relate the technique to the context of similar work.},
	number = {2},
	urldate = {2013-11-08},
	journal = {Journal of Systems and Software},
	author = {Lung, Chung-Horng and Zaman, Marzia and Nandi, Amit},
	month = oct,
	year = {2004},
	keywords = {clustering, Cohesion and coupling, Design recovery, Evolution, Restructuring, reverse engineering, Software partitioning},
	pages = {227--244},
	file = {ScienceDirect Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/NSE33FUK/Lung et al. - 2004 - Applications of clustering techniques to software .pdf:application/pdf;ScienceDirect Snapshot:/Users/dcutting/Dropbox/PhD/Zotero/storage/N56TAG4A/S0164121203002346.html:text/html}
},

@inproceedings{bauer_architecture-aware_2004,
	title = {Architecture-aware adaptive clustering of {OO} systems},
	doi = {10.1109/CSMR.2004.1281401},
	abstract = {The recovery of software architecture is a first important step towards re-engineering a software system. Architecture recovery usually involves clustering. The problem with current clustering techniques is that they decide exclusively based on syntactic dependencies instead of looking at higher-level semantic information. As a result, the recovered architecture is not always meaningful to a human software engineer. We propose an approach that combines clustering with pattern-matching techniques to recover meaningful decompositions. Pattern-matching is used to identify architectural clues-small structural patterns that provide semantic information to allow for a rating of the dependencies found between a system's entities. These clues are used to compute an adaptive interclass similarity measure which is then used by a clustering algorithm to produce the final system decomposition.},
	booktitle = {Eighth European Conference on Software Maintenance and Reengineering, 2004. {CSMR} 2004. Proceedings},
	author = {Bauer, M. and Trifu, M.},
	year = {2004},
	keywords = {clustering techniques, Computer architecture, Computer hacking, Computer science, Connectors, data mining, Degradation, Documentation, higher-level semantic information, human software engineer, object-oriented methods, {OO} systems, pattern clustering, pattern matching, pattern-matching techniques, reverse engineering, Software architecture, software architecture recovery, software re-engineering, Software systems, systems re-engineering},
	pages = {3--14},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/WWB35GA5/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/ZWGPCJWV/Bauer and Trifu - 2004 - Architecture-aware adaptive clustering of OO syste.pdf:application/pdf}
},

@inproceedings{doval_automatic_1999,
	title = {Automatic clustering of software systems using a genetic algorithm},
	doi = {10.1109/STEP.1999.798481},
	abstract = {Large software systems tend to have a rich and complex structure. Designers typically depict the structure of software systems as one or more directed graphs. For example, a directed graph can be used to describe the modules (or classes) of a system and their static interrelationships using nodes and directed edges, respectively. We call such graphs “module dependency graphs” ({MDGs).} {MDGs} can be large and complex graphs. One way of making them more accessible is to partition them, separating their nodes (i.e. modules) into clusters (i.e. subsystems). In this paper, we describe a technique for finding “good” {MDG} partitions. Good partitions feature relatively independent subsystems that contain modules which are highly interdependent. Our technique treats finding a good partition as an optimization problem, and uses a genetic algorithm ({GA)} to search the extraordinarily large solution space of all possible {MDG} partitions. The effectiveness of our technique is demonstrated by applying it to a medium-sized software system},
	booktitle = {Software Technology and Engineering Practice, 1999. {STEP} '99. Proceedings},
	author = {Doval, D. and Mancoridis, S. and Mitchell, {B.S.}},
	year = {1999},
	keywords = {automatic clustering, Computer science, directed edges, directed graphs, genetic algorithm, genetic algorithms, graph node clusters, graph partitioning, independent subsystems, interdependent modules, large software systems, Mathematics, medium-sized software system, module dependency graphs, module subsystems, optimization, reverse engineering, search problems, Software architecture, Software design, Software Engineering, Software systems, solution space searching, static interrelationships, subroutines},
	pages = {73--81},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/6KCJCU3Z/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/E2IDDSJ7/Doval et al. - 1999 - Automatic clustering of software systems using a g.pdf:application/pdf}
},

@inproceedings{rousidis_clustering_2005,
	title = {Clustering Data Retrieved from Java Source Code to Support Software Maintenance: A Case Study},
	shorttitle = {Clustering Data Retrieved from Java Source Code to Support Software Maintenance},
	doi = {10.1109/CSMR.2005.16},
	abstract = {Data mining is a technology recently used in support of software maintenance in various contexts. Our works focuses on achieving a high level understanding of Java systems without prior familiarity with these. Our thesis is that system structure and interrelationships, as well as similarities among program components can be derived by applying cluster analysis on data extracted from source code. This paper proposes a methodology suitable for Java code analysis. It comprises of a Java code analyser which examines programs and constructs tables representing code syntax, and a clustering engine which operates on such tables and identifies relationships among code elements. We evaluate the methodology on a medium sized system, present initial results and discuss directions for further work.},
	booktitle = {Ninth European Conference on Software Maintenance and Reengineering, 2005. {CSMR} 2005},
	author = {Rousidis, D. and Tjortjis, Christos},
	year = {2005},
	keywords = {cluster analysis, computer aided software engineering, data analysis, data cluster, data extraction, data mining, Data models, Engines, Informatics, Information retrieval, Java, Java code analysis, Java source code, software maintenance, Spatial databases, system monitoring},
	pages = {276--279},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/8Q33EWCX/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/I7NAJR54/Rousidis and Tjortjis - 2005 - Clustering Data Retrieved from Java Source Code to.pdf:application/pdf}
},

@article{shtern_clustering_2012,
	title = {Clustering methodologies for software engineering},
	volume = {2012},
	issn = {1687-8655},
	url = {http://dx.doi.org/10.1155/2012/792024},
	doi = {10.1155/2012/792024},
	abstract = {The size and complexity of industrial strength software systems are constantly increasing. This means that the task of managing a large software project is becoming even more challenging, especially in light of high turnover of experienced personnel. Software clustering approaches can help with the task of understanding large, complex software systems by automatically decomposing them into smaller, easier-to-manage subsystems. The main objective of this paper is to identify important research directions in the area of software clustering that require further attention in order to develop more effective and efficient clustering methodologies for software engineering. To that end, we first present the state of the art in software clustering research. We discuss the clustering methods that have received the most attention from the research community and outline their strengths and weaknesses. Our paper describes each phase of a clustering algorithm separately. We also present the most important approaches for evaluating the effectiveness of software clustering.},
	urldate = {2013-11-08},
	journal = {Adv. Soft. Eng.},
	author = {Shtern, Mark and Tzerpos, Vassilios},
	month = jan,
	year = {2012},
	pages = {1:1–1:1}
},

@inproceedings{beyer_clustering_2005,
	title = {Clustering software artifacts based on frequent common changes},
	doi = {10.1109/WPC.2005.12},
	abstract = {Changes of software systems are less expensive and less error-prone if they affect only one subsystem. Thus, clusters of artifacts that are frequently changed together are subsystem candidates. We introduce a two-step method for identifying such clusters. First, a model of common changes of software artifacts, called co-change graph, is extracted from the version control repository of the software system. Second, a layout of the co-change graph is computed that reveals clusters of frequently co-changed artifacts. We derive requirements for such layouts, and introduce an energy model for producing layouts that fulfill these requirements. We evaluate the method by applying it to three example systems, and comparing the resulting layouts to authoritative decompositions.},
	booktitle = {13th International Workshop on Program Comprehension, 2005. {IWPC} 2005. Proceedings},
	author = {Beyer, D. and Noack, A.},
	year = {2005},
	keywords = {Application software, cluster identification, Clustering methods, co-change graph layout, configuration management, Costs, data flow graphs, Documentation, File systems, formal specification, frequently co-changed artifact cluster, Power engineering and energy, program understanding, requirement analysis, reverse engineering, software artifact clustering, software maintenance, software system change management, Software systems, subsystem candidate, Systems engineering and theory, version control repository},
	pages = {259--268},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/BUEIUZN6/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/88RERPZC/Beyer and Noack - 2005 - Clustering software artifacts based on frequent co.pdf:application/pdf}
},

@inproceedings{telea_code_2008,
	title = {Code flows: Visualizing structural evolution of source code},
	volume = {27},
	shorttitle = {Code flows},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2008.01214.x/full},
	urldate = {2013-11-12},
	booktitle = {Computer Graphics Forum},
	author = {Telea, Alexandru and Auber, David},
	year = {2008},
	pages = {831–838},
	file = {j.1467-8659.2008.01214.pdf:/Users/dcutting/Dropbox/PhD/Zotero/storage/U4RD3KRJ/j.1467-8659.2008.01214.pdf:application/pdf}
},

@article{jaafar_detecting_2013,
	title = {Detecting asynchrony and dephase change patterns by mining software repositories},
	copyright = {Copyright © 2013 John Wiley \& Sons, Ltd.},
	issn = {2047-7481},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/smr.1635/abstract},
	doi = {10.1002/smr.1635},
	abstract = {Software maintenance accounts for the largest part of the costs of any program. During maintenance activities, developers implement changes (sometimes simultaneously) on artifacts in order to fix bugs and to implement new requirements. To reduce this part of the costs, previous work proposed approaches to identify the artifacts of programs that change together. These approaches analyze historical data, mined from version control systems, and report change patterns, which lead at the causes, consequences, and actors of the changes to source code files. They also introduce so-called change patterns that describe some typical change dependencies among files. In this paper, we introduce two novel change patterns: the asynchrony change pattern, corresponding to macro co-changes ({MC)}, that is, of files that co-change within a large time interval (change periods) and the dephase change pattern, corresponding to dephase macro co-changes ({DC)}, that is, {MC} that always happens with the same shifts in time. We present our approach, that we named Macocha, to identify these two change patterns in large programs. We use the k-nearest neighbor algorithm to group changes into change periods. We also use the Hamming distance to detect approximate occurrences of {MC} and {DC.} We apply Macocha and compare its performance in terms of precision and recall with {UMLDiff} (file stability) and association rules (co-changing files) on seven systems: {ArgoUML}, {FreeBSD}, {JFreeChart}, Openser, {SIP}, {XalanC}, and {XercesC} developed with three different languages (C, C++, and Java). These systems have a size ranging from 532 to 1693 files, and during the study period, they have undergone 1555 to 23,944 change commits. We use external information and static analysis to validate (approximate) {MC} and {DC} found by Macocha. Through our case study, we show the existence and usefulness of these novel change patterns to ease software maintenance and, potentially, reduce related costs. Copyright © 2013 John Wiley \& Sons, Ltd.},
	language = {en},
	urldate = {2013-11-08},
	journal = {Journal of Software: Evolution and Process},
	author = {Jaafar, Fehmi and Guéhéneuc, Yann-Gaël and Hamel, Sylvie and Antoniol, Giuliano},
	year = {2013},
	keywords = {bit vectors, change pattern, change period, co-changes, stability},
	pages = {n/a–n/a},
	file = {Snapshot:/Users/dcutting/Dropbox/PhD/Zotero/storage/RMR9EVHV/abstract.html:text/html}
},

@inproceedings{mcmillan_detecting_2012,
	title = {Detecting similar software applications},
	doi = {10.1109/ICSE.2012.6227178},
	abstract = {Although popular text search engines allow users to retrieve similar web pages, source code search engines do not have this feature. Detecting similar applications is a notoriously difficult problem, since it implies that similar highlevel requirements and their low-level implementations can be detected and matched automatically for different applications. We created a novel approach for automatically detecting Closely {reLated} {ApplicatioNs} ({CLAN)} that helps users detect similar applications for a given Java application. Our main contributions are an extension to a framework of relevance and a novel algorithm that computes a similarity index between Java applications using the notion of semantic layers that correspond to packages and class hierarchies. We have built {CLAN} and we conducted an experiment with 33 participants to evaluate {CLAN} and compare it with the closest competitive approach, {MUDABlue.} The results show with strong statistical significance that {CLAN} automatically detects similar applications from a large repository of 8,310 Java applications with a higher precision than {MUDABlue.}},
	booktitle = {2012 34th International Conference on Software Engineering ({ICSE)}},
	author = {{McMillan}, C. and Grechanik, M. and Poshyvanyk, D.},
	year = {2012},
	keywords = {{CLAN}, class hierarchy, closely related application detection, Java, Java application, Large scale integration, {MUDABlue}, packages hierarchy, Search engines, semantic layers, Semantics, similar software application detection, Software, Software Engineering, source code search engines, statistical analysis, text search engines, Time division multiplexing, Vectors, Web page retrieval},
	pages = {364--374},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/CRCXMU5A/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/F6FKHD9W/McMillan et al. - 2012 - Detecting similar software applications.pdf:application/pdf}
},

@inproceedings{kuhn_enriching_2005,
	title = {Enriching reverse engineering with semantic clustering},
	doi = {10.1109/WCRE.2005.16},
	abstract = {Understanding a software system by just analyzing the structure of the system reveals only half of the picture, since the structure tells us only how the code is working but not what the code is about. What the code is about can be found in the semantics of the source code: names of identifiers, comments etc. In this paper, we analyze how these terms are spread over the source artifacts using latent semantic indexing, an information retrieval technique. We use the assumption that parts of the system that use similar terms are related. We cluster artifacts that use similar terms, and we reveal the most relevant terms for the computed clusters. Our approach works at the level of the source code which makes it language independent. Nevertheless, we correlated the semantics with structural information and we applied it at different levels of abstraction (e.g. classes, methods). We applied our approach on three large case studies and we report the results we obtained.},
	booktitle = {12th Working Conference on Reverse Engineering},
	author = {Kuhn, A. and Ducasse, S. and Girba, T.},
	year = {2005},
	keywords = {artifacts clustering, clustering, Computational modeling, Computer simulation, concept location, formal specification, Indexing, Information analysis, Information retrieval, Large scale integration, latent semantic indexing, program diagnostics, programming language semantics, reverse engineering, semantic analysis, semantic clustering, software system, Software systems, source code semantic, structured programming, system structure, Vocabulary, Web server},
	pages = {10 pp.--},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/6SKI49E9/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/R3KK7JE3/Kuhn et al. - 2005 - Enriching reverse engineering with semantic cluste.pdf:application/pdf}
},

@inproceedings{fischer_evograph:_2006,
	title = {{EvoGraph:} A Lightweight Approach to Evolutionary and Structural Analysis of Large Software Systems},
	shorttitle = {{EvoGraph}},
	doi = {10.1109/WCRE.2006.26},
	abstract = {Structural analyses frequently fall short in an adequate representation of historical changes for retrospective analysis. By compounding the two underlying information spaces in a single approach, the comprehension about the interaction between evolving requirements and system development can be improved significantly. We therefore propose a lightweight approach based on release history data and source code changes, which first selects entities with evolutionary outstanding characteristics and then indicates their structural dependencies via commonly used source code entities. The resulting data sets and visualizations aim at a holistic view to point out and assess structural stability, recurring modifications, or changes in the dependencies of the file-sets under inspection. In this paper we describe our approach and its results in terms of the Mozilla case study. Our approach completes typical release history mining and source code analysis approaches, therefore past restructuring events, new, shifted, and removed dependencies can be spotted easily},
	booktitle = {13th Working Conference on Reverse Engineering, 2006. {WCRE} '06},
	author = {Fischer, M. and Gall, H.},
	year = {2006},
	keywords = {Computer architecture, data mining, data sets, Data visualization, data visualizations, {EvoGraph}, evolutionary analysis, Frequency, graph theory, History, Informatics, Inspection, large software systems, Mozilla case study, Open source software, program diagnostics, program visualisation, retrospective analysis, Software systems, source code analysis, source code entity, structural analysis, Structural engineering, system development, systems analysis},
	pages = {179--188},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/WT7X3FUQ/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/CKMFTTPC/Fischer and Gall - 2006 - EvoGraph A Lightweight Approach to Evolutionary a.pdf:application/pdf}
},

@article{lungu_evolutionary_2014,
	title = {Evolutionary and collaborative software architecture recovery with Softwarenaut},
	volume = {79},
	issn = {0167-6423},
	url = {http://www.sciencedirect.com/science/article/pii/S0167642312000718},
	doi = {10.1016/j.scico.2012.04.007},
	abstract = {Architecture recovery is an activity applied to a system whose initial architecture has eroded. When the system is large, the user must use dedicated tools to support the recovery process. We present Softwarenaut — a tool which supports architecture recovery through interactive exploration and visualization. Classical architecture recovery features, such as filtering and details on demand, are enhanced with evolutionary capabilities when multi-version information about a subject system is available. The tool allows sharing and discovering the results of previous analysis sessions through a global repository of architectural views indexed by systems.

We present the features of the tool together with the architecture recovery process that it supports using as a case-study {ArgoUML}, a well-known open source Java system.},
	urldate = {2013-11-08},
	journal = {Science of Computer Programming},
	author = {Lungu, Mircea and Lanza, Michele and Nierstrasz, Oscar},
	month = jan,
	year = {2014},
	keywords = {Architecture recovery, reverse engineering, software tools, Visualization},
	pages = {204--223},
	file = {ScienceDirect Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/RMV7R7FU/Lungu et al. - 2014 - Evolutionary and collaborative software architectu.pdf:application/pdf;ScienceDirect Snapshot:/Users/dcutting/Dropbox/PhD/Zotero/storage/A8PTJZAW/S0167642312000718.html:text/html}
},

@inproceedings{zaidman_mining_2008,
	title = {Mining Software Repositories to Study Co-Evolution of Production \#x00026; Test Code},
	doi = {10.1109/ICST.2008.47},
	abstract = {Engineering software systems is a multidisciplinary activity, whereby a number of artifacts must be created - and maintained - synchronously. In this paper we investigate whether production code and the accompanying tests co- evolve by exploring a project's versioning system, code coverage reports and size-metrics. Our main aim for studying this co-evolution is to create awareness with developers and managers alike about the testing process that is followed. We explore the possibilities of our technique through two open source case studies and observe a number of different co-evolution scenarios. We evaluate our results both with the help of log-messages and the original developers of the software system.},
	booktitle = {2008 1st International Conference on Software Testing, Verification, and Validation},
	author = {Zaidman, A. and Van Rompaey, B. and Demeyer, S. and van Deursen, A.},
	year = {2008},
	keywords = {code coverage reports, configuration management, data mining, Life testing, Maintenance engineering, mining software repositories, Multidimensional systems, Open source software, production \& test code co-evolution, Production systems, program testing, project versioning system, size-metrics, software co-evolution, Software evolution, software maintenance, software metrics, software prototyping, Software quality, Software repository mining, Software systems, Software testing, System testing, Systems engineering and theory},
	pages = {220--229},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/9R3X6BJF/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/74SANWU8/Zaidman et al. - 2008 - Mining Software Repositories to Study Co-Evolution.pdf:application/pdf}
},

@article{beck_impact_2013,
	title = {On the impact of software evolution on software clustering},
	volume = {18},
	issn = {1382-3256, 1573-7616},
	url = {http://link.springer.com/article/10.1007/s10664-012-9225-9},
	doi = {10.1007/s10664-012-9225-9},
	abstract = {The evolution of a software project is a rich data source for analyzing and improving the software development process. Recently, several research groups have tried to cluster source code artifacts based on information about how the code of a software system evolves. The results of these evolutionary approaches seem promising, but a direct comparison to traditional software clustering approaches based on structural code dependencies is still missing. To fill this gap, we conducted several clustering experiments with an established software clustering tool comparing and combining the evolutionary and the structural approach. These experiments show that the evolutionary approach could produce meaningful clustering results. While the traditional approach provides better results because of a more reliable data density of the structural data, the combination of both approaches is able to improve the overall clustering quality. A review of related studies shows that this approach of combining dependency information is also successful in other software engineering applications.},
	language = {en},
	number = {5},
	urldate = {2013-11-12},
	journal = {Empirical Software Engineering},
	author = {Beck, Fabian and Diehl, Stephan},
	month = oct,
	year = {2013},
	keywords = {Code dependencies, empirical study, Programming Languages, Compilers, Interpreters, Software clustering, Software {Engineering/Programming} and Operating Systems, Software evolution},
	pages = {970--1004},
	file = {Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/4SMSI522/Beck and Diehl - 2013 - On the impact of software evolution on software cl.pdf:application/pdf;Snapshot:/Users/dcutting/Dropbox/PhD/Zotero/storage/RX9AV8NE/s10664-012-9225-9.html:text/html}
},

@inproceedings{tangsripairoj_organizing_2005,
	address = {New York, {NY}, {USA}},
	series = {{SAC} '05},
	title = {Organizing and visualizing software repositories using the growing hierarchical self-organizing map},
	isbn = {1-58113-964-0},
	url = {http://doi.acm.org/10.1145/1066677.1067023},
	doi = {10.1145/1066677.1067023},
	abstract = {A software repository, a place where reusable components are stored and searched for, is a key ingredient for instituting and popularizing software reuse. It is vital that a software repository should be well-organized and provide efficient tools for developers to locate reusable components that meet their requirements. The growing hierarchical self-organizing map ({GHSOM)}, an unsupervised learning neural network, is a powerful data mining technique for the clustering and visualization of large and complex data sets. The resulting maps, serving as retrieval interfaces, can be beneficial to developers in obtaining better insight into the structure of a software repository and increasing their understanding of the relationships among software components. The {GHSOM}, which is an improvement over the basic self-organizing map ({SOM)}, can adapt its architecture during its learning process and expose the hierarchical structure that exists in the original data. In this paper, we demonstrate the potential of the {GHSOM} for the organization and visualization of a collection of reusable components stored in a software repository, and compare the results with the ones obtained by using the traditional {SOM.}},
	urldate = {2013-11-12},
	booktitle = {Proceedings of the 2005 {ACM} symposium on Applied computing},
	publisher = {{ACM}},
	author = {Tangsripairoj, Songsri and Samadzadeh, M. H.},
	year = {2005},
	keywords = {growing hierarchical self-organizing map, self-organizing map, software repository, software reuse},
	pages = {1539–1545},
	file = {ACM Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/ZC42HJVW/Tangsripairoj and Samadzadeh - 2005 - Organizing and visualizing software repositories u.pdf:application/pdf}
},

@article{inoue_ranking_2005,
	title = {Ranking significance of software components based on use relations},
	volume = {31},
	issn = {0098-5589},
	doi = {10.1109/TSE.2005.38},
	abstract = {Collections of already developed programs are important resources for efficient development of reliable software systems. In this paper, we propose a novel graph-representation model of a software component library (repository), called component rank model. This is based on analyzing actual usage relations of the components and propagating the significance through the usage relations. Using the component rank model, we have developed a Java class retrieval system named {SPARS-J} and applied {SPARS-J} to various collections of Java files. The result shows that {SPARS-J} gives a higher rank to components that are used more frequently. As a result, software engineers looking for a component have a better chance of finding it quickly. {SPARS-J} has been used by two companies, and has produced promising results.},
	number = {3},
	journal = {{IEEE} Transactions on Software Engineering},
	author = {Inoue, K. and Yokomori, R. and Yamamoto, T. and Matsushita, M. and Kusumoto, S.},
	year = {2005},
	keywords = {Application software, Companies, component rank model, graph representation model, graph-representation model, Index Terms- Component rank, Information analysis, Information retrieval, Internet, Java, Java class retrieval system, program analysis, program diagnostics, Programming, reusable libraries., reuse models, software component library, Software libraries, Software quality, software reusability, Software systems},
	pages = {213--225},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/DS6XTZWE/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/AD6RX83Z/Inoue et al. - 2005 - Ranking significance of software components based .pdf:application/pdf}
},

@inproceedings{dambros_reverse_2006,
	title = {Reverse Engineering with Logical Coupling},
	doi = {10.1109/WCRE.2006.51},
	abstract = {Evolutionary information about software systems has proven to be a good resource to complement existing reverse engineering approaches, because it helps in giving a historical perspective of the system to be reverse engineered. Moreover, it provides additional types of information that are not present when only one version of a system is considered. Logical coupling, the implicit dependency between artifacts which changed together, is one example of such information. However, the recurrent problem is that such information comes in large amounts and must be processed to be useful for the reverse engineering of a system. In this paper we propose an approach to use logical coupling information at different levels of abstraction to detect areas in the system which may lead to maintenance problems. They represent a good starting point to decrease the coupling in the system. Our approach uses an interactive visualization technique called the Evolution Radar, which can effectively break down the amount and complexity of the logical coupling information. We present our technique in detail and apply it on a large open-source software system},
	booktitle = {13th Working Conference on Reverse Engineering, 2006. {WCRE} '06},
	author = {{D'Ambros}, M. and Lanza, M.},
	year = {2006},
	keywords = {Evolution Radar, evolutionary computation, evolutionary information, History, Informatics, interactive visualization technique, logical coupling, Open source software, open-source software system, Optical coupling, Packaging, program visualisation, public domain software, Radar detection, reverse engineering, software maintenance, Software packages, Software systems, Visualization},
	pages = {189--198},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/E8WE6VQR/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/9NRB7H2J/D'Ambros and Lanza - 2006 - Reverse Engineering with Logical Coupling.pdf:application/pdf}
},

@article{kuhn_semantic_2007,
	title = {Semantic clustering: Identifying topics in source code},
	volume = {49},
	issn = {0950-5849},
	shorttitle = {Semantic clustering},
	url = {http://www.sciencedirect.com/science/article/pii/S0950584906001820},
	doi = {10.1016/j.infsof.2006.10.017},
	abstract = {Many of the existing approaches in Software Comprehension focus on program structure or external documentation. However, by analyzing formal information the informal semantics contained in the vocabulary of source code are overlooked. To understand software as a whole, we need to enrich software analysis with the developer knowledge hidden in the code naming. This paper proposes the use of information retrieval to exploit linguistic information found in source code, such as identifier names and comments. We introduce Semantic Clustering, a technique based on Latent Semantic Indexing and clustering to group source artifacts that use similar vocabulary. We call these groups semantic clusters and we interpret them as linguistic topics that reveal the intention of the code. We compare the topics to each other, identify links between them, provide automatically retrieved labels, and use a visualization to illustrate how they are distributed over the system. Our approach is language independent as it works at the level of identifier names. To validate our approach we applied it on several case studies, two of which we present in this paper.

Note: Some of the visualizations presented make heavy use of colors. Please obtain a color copy of the article for better understanding.},
	number = {3},
	urldate = {2013-11-08},
	journal = {Information and Software Technology},
	author = {Kuhn, Adrian and Ducasse, Stéphane and Gîrba, Tudor},
	month = mar,
	year = {2007},
	keywords = {clustering, latent semantic indexing, reverse engineering, Visualization},
	pages = {230--243},
	file = {ScienceDirect Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/4ZWQ9XIK/Kuhn et al. - 2007 - Semantic clustering Identifying topics in source .pdf:application/pdf;ScienceDirect Snapshot:/Users/dcutting/Dropbox/PhD/Zotero/storage/3CSDMAZU/S0950584906001820.html:text/html}
},

@inproceedings{alkhalid_software_2013,
	title = {Software architecture decomposition using adaptive K-nearest neighbor algorithm},
	doi = {10.1109/CCECE.2013.6567812},
	abstract = {Software architecture decomposition plays an important role in software design cascading effect on various development phases. Software designer decomposes software based on his/her experience. Though it may work well for some, in reality many systems failed to meet the requirements as a result of poor design. Software architecture decomposition using clustering techniques has been investigated in software engineering research. This paper presents an enhanced approach for software architecture decomposition. We used two hierarchical agglomerative clustering methods and adaptive K-nearest neighbor algorithm in this enhanced approach and applied it on two industrial software systems. Results show that the approach provides objective and insightful information for software designer.},
	booktitle = {2013 26th Annual {IEEE} Canadian Conference on Electrical and Computer Engineering ({CCECE)}},
	author = {Alkhalid, A. and Lung, Chung-Horng and Ajila, S.},
	year = {2013},
	keywords = {adaptive k-nearest neighbor algorithm, Algorithms, clustering, Clustering algorithms, Design Software Architecture, development phase, hierarchical agglomerative clustering methods, industrial software systems, Lungs, manufacturing data processing, pattern clustering, Pattern Recognition, Protocols, Software algorithms, Software architecture, software architecture decomposition, software design cascading effect, software designer, software engineering research, Software systems},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/IWRHN7TI/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/PITDPD54/Alkhalid et al. - 2013 - Software architecture decomposition using adaptive.pdf:application/pdf}
},

@article{praditwong_software_2011,
	title = {Software Module Clustering as a Multi-Objective Search Problem},
	volume = {37},
	issn = {0098-5589},
	doi = {10.1109/TSE.2010.26},
	abstract = {Software module clustering is the problem of automatically organizing software units into modules to improve program structure. There has been a great deal of recent interest in search-based formulations of this problem in which module boundaries are identified by automated search, guided by a fitness function that captures the twin objectives of high cohesion and low coupling in a single-objective fitness function. This paper introduces two novel multi-objective formulations of the software module clustering problem, in which several different objectives (including cohesion and coupling) are represented separately. In order to evaluate the effectiveness of the multi-objective approach, a set of experiments was performed on 17 real-world module clustering problems. The results of this empirical study provide strong evidence to support the claim that the multi-objective approach produces significantly better solutions than the existing single-objective approach.},
	number = {2},
	journal = {{IEEE} Transactions on Software Engineering},
	author = {Praditwong, K. and Harman, M. and Yao, Xin},
	year = {2011},
	keywords = {evolutionary computation., module clustering, multi-objective optimization, multi-objective search problem, optimisation, pattern clustering, program structure, {SBSE}, search problems, Software Engineering, software module clustering},
	pages = {264--282},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/CJWKA7FN/abs_all.html:text/html}
},

@article{ouni_use_2013,
	title = {The Use of Development History in Software Refactoring Using a Multi-Objective Evolutionary Algorithm},
	url = {http://icese.bis-cmt.com/GECCO2013.pdf},
	urldate = {2013-11-12},
	author = {Ouni, Ali and Kessentini, Marouane and Sahraoui, Houari and Hamdi, Mohamed Salah},
	year = {2013},
	file = {GECCO2013.pdf:/Users/dcutting/Dropbox/PhD/Zotero/storage/QVJJAKJN/GECCO2013.pdf:application/pdf}
},

@article{bock_uml_2003,
	title = {{UML} without pictures},
	volume = {20},
	issn = {0740-7459},
	doi = {10.1109/MS.2003.1231148},
	abstract = {This article reviews the concepts of repository-centered development with {UML}, explaining how notation, semantics, and model compilation relate. {UML} can be used in many formats, including presented as text, parsed into a standardized repository, and compiled to multiple programming languages. The example given uses the {UML} 2 repository.},
	number = {5},
	journal = {{IEEE} Software},
	author = {Bock, C.},
	year = {2003},
	keywords = {model compilation, notation, program compilers, programming language semantics, programming languages, repository-centered architecture, repository-centered development, Semantics, specification languages, {UML}, {UML} 2 repository, Unified modeling language},
	pages = {33--35},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/T5R8HCIE/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/TKSWPKTD/Bock - 2003 - UML without pictures.pdf:application/pdf}
},

@inproceedings{neamtiu_understanding_2005,
	address = {New York, {NY}, {USA}},
	series = {{MSR} '05},
	title = {Understanding source code evolution using abstract syntax tree matching},
	isbn = {1-59593-123-6},
	url = {http://doi.acm.org/10.1145/1082983.1083143},
	doi = {10.1145/1082983.1083143},
	abstract = {Mining software repositories at the source code level can provide a greater understanding of how software evolves. We present a tool for quickly comparing the source code of different versions of a C program. The approach is based on partial abstract syntax tree matching, and can track simple changes to global variables, types and functions. These changes can characterize aspects of software evolution useful for answering higher level questions. In particular, we consider how they could be used to inform the design of a dynamic software updating system. We report results based on measurements of various versions of popular open source programs. including {BIND}, {OpenSSH}, Apache, Vsftpd and the Linux kernel.},
	urldate = {2013-11-08},
	booktitle = {Proceedings of the 2005 international workshop on Mining software repositories},
	publisher = {{ACM}},
	author = {Neamtiu, Iulian and Foster, Jeffrey S. and Hicks, Michael},
	year = {2005},
	keywords = {abstract syntax trees, Software evolution, source code analysis},
	pages = {1–5}
},

@inproceedings{mancoridis_using_1998,
	title = {Using automatic clustering to produce high-level system organizations of source code},
	doi = {10.1109/WPC.1998.693283},
	abstract = {We describe a collection of algorithms that we developed and implemented to facilitate the automatic recovery of the modular structure of a software system from its source code. We treat automatic modularization as an optimization problem. Our algorithms make use of traditional hill-climbing and genetic algorithms},
	booktitle = {, 6th International Workshop on Program Comprehension, 1998. {IWPC} '98. Proceedings},
	author = {Mancoridis, S. and Mitchell, {B.S.} and Rorres, C. and Chen, Y. and Gansner, {E.R.}},
	year = {1998},
	keywords = {automatic clustering, automatic modularization, Clustering algorithms, Computer science, genetic algorithms, graph theory, high-level system organizations, hill-climbing algorithms, Mathematics, optimization problem, Programming profession, reverse engineering, Software algorithms, Software Engineering, software maintenance, software structure recovery, Software systems, source code, Visual databases, Visualization},
	pages = {45--52},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/A8EZIA2B/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/U6BBVNUC/Mancoridis et al. - 1998 - Using automatic clustering to produce high-level s.pdf:application/pdf}
},

@inproceedings{mutton_visualization_2003,
	title = {Visualization of semantic metadata and ontologies},
	doi = {10.1109/IV.2003.1217994},
	abstract = {Implicit information embedded in semantic Web graphs, such as topography, clusters, and disconnected subgraphs is difficult to extract from text files. Visualizations of the graphs can reveal some of these features, but existing systems for visualizing metadata focus on aspects other than understanding the greater structure. We present a tool for generating visualizations of ontologies and metadata by using a modified spring embedder to achieve an automatic layout. Through a case study using a mid-sized ontology, we show that interesting information about the data relationships can be extracted through our visualization of the physical graph structure.},
	booktitle = {Seventh International Conference on Information Visualization, 2003. {IV} 2003. Proceedings},
	author = {Mutton, P. and Golbeck, J.},
	year = {2003},
	keywords = {data mining, Data models, data relationship, data visualisation, Data visualization, disconnected subgraph, Educational institutions, entity-relationship modelling, graph theory, graph visualization, Information resources, meta data, Microstrip, modified spring embedder, Ontologies, ontology, physical graph structure, Resource description framework, semantic metadata visualization, semantic Web, semantic Web graph, Springs, Surfaces, text file, topography},
	pages = {300--305},
	file = {IEEE Xplore Abstract Record:/Users/dcutting/Dropbox/PhD/Zotero/storage/F9GVK46H/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/dcutting/Dropbox/PhD/Zotero/storage/CC9M92RZ/Mutton and Golbeck - 2003 - Visualization of semantic metadata and ontologies.pdf:application/pdf}
}

